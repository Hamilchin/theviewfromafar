<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8">
        <title>Unsorted thoughts</title>
    </head>
    <body style="width: 600px; margin: 0 auto; text-align: left;">
        <pre>
        <h2>Unsorted thoughts</h2>
        </pre>
        
        <p>What must be done must be done. </p>
<p>Crusty busty 40 y/o. </p>
<p>A lot of suffering comes from the subconscious feeling that if you lose something, you will be left with nothing. Social anxiety is very related with low self-confidence. </p>
<p><em>Write as true as a straight arrow.</em> </p>
<p>More interesting ideas: <br />
Organisms are the cost function calculation vehicles for genes. </p>
<p>The size of storage in a microSD card. </p>
<p>to encode a lot of information in a little bit of space, you need recursion. This is what humans do to encode everything in 100 MB of space. </p>
<p>Every person wants a partner that will fulfill <em>their</em> biological imperative. Love is selfish. </p>
<script data-goatcounter="https://hamilchin.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>

<p>Central question to answer: what is complexity?</p>
<p>Effective complexity is subjective. Effective complexity at every level is not. How about hybrid complexity? <br />
Assume your program has access to a “true random” generator- how likely is it to sample? Adapted solomonoff-effective. </p>
<p>How hard something is to make; I.e. how much raw incompressible optimized computational power (in terms of time) you need to compute something. Logical depth is the time-complexity equivalent of k-complexity. But to do this you need to define “properly programmed” - that is, one that has a generalizable structure (?)</p>
<p>There are two ways you can go if you keep asking "but why x"? <br />
If x is true, you get to the laws of physics. <br />
If x is false or incompletely defined, you get to philosophy. </p>
<p>Recursive definitions can increase the complexity of a set (membership of a point in the set, distance from the set, ...) considerably. Recursive things open the door to infinity. </p>
<p>Do neural networks have some fundamental incompressibility? Is interpretability fundamentally hopeless? Here's the problem; knowing how evolution works does not tell us how the brain works. There is emergent complex behavior. </p>
<p>The brain has a biological/evolutionary imperative to be as space-efficient as possible. If it could have been further compressed, it would have (assuming some incorrect assumptions like that the brain is wholly focused on minimizing space-complexity but not time-complexity). But if you optimize for time-complexity, there can be some reduction in space. It seems like a tradeoff. </p>
<p>"I don't know what's good, but this certainly isn't it" is not going to work as a motto going forward. </p>
<p>From GPT Deep research, run on previous thoughts:</p>
<p>research von Neumann entropy, <strong>Universal Wavefunction</strong></p>
<p>Entropy is a measure of ignorance; it exists by virtue of approximation. </p>
<p>"all spins are randomly up or down with equal probability” is a short description of a high-entropy macrostate. </p>
<p>Murray Gell-Mann and Seth Lloyd’s notion of <strong>effective complexity</strong></p>
<p>Shannon entropy assumes the non-existence of a true random generator. Effective entropy does not. </p>
<p><strong>statistical complexity</strong> (the amount of memory needed to model a process) often peaks at intermediate disorder.</p>
<p>Maybe measure statistical complexity as a function of both time and space? <br />
What is a good generator of statistical complexity? Fractals? Sure, but only if you don't have access to a higher-level description. I.e. trying to specify every point on the mandelbrot set is impossible, but specifying it in a few function lines is easy. Fractals are simple, not complex in the higher-level meta sense. </p>
<p>What is something that is impossible to model? It would have to be incomputable. Unfortunately the universe feels a lot like a computer to me. </p>
<p>Coarse-graining; fractals retain their complexity when coarse-grained. </p>
<p>Gregory Chaitin, who introduced <strong>algorithmic randomness</strong> and showed that certain facts (like the binary digits of the halting probability Ω) are algorithmically irreducible. </p>
<p><strong>Stephen Hawking</strong> in 2002 gave a lecture titled <em>“Gödel and the End of Physics.”</em> He speculated that the quest for a complete “Theory of Everything” might be thwarted by a kind of Gödelian incompleteness if the theory, when it includes observers, becomes self-referential.</p>
<p>Good idea to run GPT deep research on any new ideas, to find existing research. </p>
<p>I’ve tried to zoom out- to see the full picture- my whole life. Perhaps it will never, ever, end.</p>
<p>Evolution is an optimizer towards stability. Yet from it, arises complexity? How? </p>
<p>entropy comes from propagating asymmetry. It is a fact underlying chaos; chaotic systems have increases in entropy. </p>
<p>Ball in well reaches low-entropy, by virtue of giving high entropy to the well through heat. But the total entropy of the system increases. Can we use this to derive the rest of physics? Can we understand the universe top-down rather than bottom-up? </p>
<p>Komolgorov complexity of both thermodynamics and basic laws of physics are very low. But they exist on completely opposite sides of a system! Laws of basic things are deterministic. Laws of emergent thighs are probabilistic. Chaos is probabilistic. It is compressible, not totally, but probabilistically. </p>
<p>What would happen if it wasn’t compressible? What would be violated?<br />
What would happen if probabilities were different, so entropy no longer always holds?<br />
Can we get any new physics from Maxwell’s demon? </p>
<p>Naive solomonoff induction only works for deterministic low level zero-noise systems. But the same mathematical principles that apply at lower levels seem to apply at higher levels! This is why machine learners can generalize on systems other than the laws of physics. </p>
<p>But are they any good at deterministic stuff? Modern ML systems have probability baked in. </p>
<p>The dichotomy appears again; prob, cont, connectionist - det, disc, symbolic. High level vs low-level. </p>
<p>We approximate entropy by assuming fundamental randomness, since chaos is intractable. Is there a way to justify it through determinism? Is this what Skye is working on? </p>
<p>The second law of thermodynamics was borne through helplessness in the face of chaos. It’s a heuristic, at best: a way to deal with the intractability of one-way functions. Maybe it’s a true law of the universe, but it certainly doesn’t deal with the dynamics of smaller subsystems, like life. </p>
<p>How does true information, that is, complexity, propagate through the universe?</p>
<p>Chaos is entropy, but a truly entropic system again becomes stable. Holy moly. Epiphany moment. This is the arrow of the universe, of any system. When you zoom out of a chaotic system it seems to become a stable system. This is because of the low Komolgorov complexity of high entropy; you can get approximate (that is, probabilistic but to an arbitrarily close degree) descriptors for a high chaos system without much complexity. You move between two poles when you zoom out, (or when time passes!!) - one pole has low entropy, low complexity, one has high entropy, low complexity, and the middle has middle entropy, high complexity! If you zoom out to include more things, the high entropy end system seems to be low entropy! This is because micro states disappear and are replaced with the macro states of the previous system. Thus zooming out, losing measurement precision, is an “equalizer” - it equalizes the defined entropy of any macrostate. </p>
<p>It’s a cycle: the highest disorder, if you zoom out, again becomes order. The k-complexity of both low level and high level systems can be very low. But in-between, you get incompressibility, irreducibility. </p>
<p>This is why it feels so intuitively weird (like in three-body), that the “barely clouds” painting has a million times more information than the detailed squares painting- because its so close to wrapping around! It’s a cycle! </p>
<p>This is also why two paints, mixed, become one paint; entropy hugely increased in the frame of reference of the paint molecules, but it decreased in the frame of reference of the color! We’ve massively increased disorder, but in a way, increased order; that is, uniformity. </p>
<p>But when the paints are in the middle of being mixed, when you get those beautiful swirls - you’ve increased the complexity of both. It is no longer reducible, in either direction. You have achieved, however briefly, true incompressibility. </p>
<p><em>Meaningful uncertainty</em> only occurs in this middle layer. In layer above, you no longer have uncertainty (but you have meaning, that is, wide scope of accurate description). In layer below, you no longer have meaningfulness, but you do have uncertainty (that is, lots of information, chaos, no way to predict behavior of individual particles). It’s a trade-off. Increase in one leads to decrease in the other. </p>
<p>At the end of the loop, when meaningfulness approaches zero, uncertainty is in full force. But once meaningfulness reaches zero, it wraps around to full- that is, once the scope of the things you can describe reaches 0, you are effectively describing everything, an infinite number of things, (meaningfulness becomes full) and uncertainty becomes 0. </p>
<p>This wraparound never truly happens, since we have quantization in particle sizes- instead we are left with a consolation prize; some low amount of uncertainty, described probabilistically rather than deterministically. The probabilistic-ness (which didn’t even exist in the layer below, since there is no true random in the layer below) becomes “true randomness” in the layer above, by virtue of this discontinuity. There is no way to address this discontinuity since our environment assumes some discreteness in particle sizes. If it didn’t, it would be incoherent. (Some relation to particle physics?). Therefore, the randomness is not “true” in the layer above- it is still deterministic via the layer below, yet in the “new frame of description” - the zoomed out frame - we must assume it comes from true randomness (or else everything becomes intractable.) It is in this gap that we go from deterministic particle physics to random thermodynamics, and the cycle “wraps around”. </p>
<p>The key idea here is that entropy does not exist independently of a level; it depends on reference frame, just as K-complexity depends on language. There is no “universal second law.” </p>
<p>Oh, and is there a relationship here to quantum mechanics? Sounds an awful lot like uncertainty principle. Not sure though. Probably not. I’ll abandon the search to derive fundamental physics from thermodynamics. </p>
<p>Wolfram probably explored this through his different cellular automata; chaotic, ordered, or complex. </p>
<p>In the middle of two voids (birth, death) lives life. In the middle of two extremes lives complexity. In the middle of unchangingness lives change. But I digress; this is straying away from physics and into philosophy (god forbid!)</p>
<p>Once a chaotic system becomes chaotic enough, it becomes stable in a probabilistic sense. </p>
<p>Do there exist chaotic systems that never become stable in a probabilistic sense? This is true good? Things that are not only unstable, but unstable, that is, complex, “at every level” - no matter how far out you zoom? Sounds awfully like a fractal. </p>
<p>Create a mathematical formalism for this; the existence of the edge of chaos, the “entropic fold.”</p>
<p>Can we prove the existence of one-way functions using chaos? </p>
<p>What is the entropy of many-worlds? It doesn’t increase at every collapse, does it? </p>
<p>We say things ordered “tend to” move towards disorder by invoking randomness, because we can’t deal with the truth of the world. </p>
<p>Moments of brief profundity, or of striking significance, come not from realizing one instance of a thing, but from realizing that something deeper has existed this whole time, something huge, immaterial. </p>
<p>Said better:</p>
<p>Something affects you not by virtue of itself existing, but because it indicates the existence of something larger that is unexpected, something you normally don't have access to, and will soon forget; the veil of the world-weight. </p>
<p>Sublime things lift the veil of the world-weight. </p>
<p>Is there a connection between computational irreducibility and one-way systems? <br />
For instance, in a computationally reducible system, there is regularity you can exploit in terms of input-&gt;output map. <br />
Ah, perhaps inverting a chaotic system is a computationally irreducible problem. For how could you find which input mapped to which output without simulating every input?</p>
<p>We see macrostates, not microstates. Knowing the entropy of a macrostate lets us know its progression - always from lower to higher entropy. </p>
<p>Do I have stable self-worth? Something to think about, to be sure. </p>
<p>Romantic attraction is not <em>merit based</em>. It's irrational. </p>
<p>I place the potential partner as a kind of symbolic validator of my exceptionalism. This is a mindset rooted in fear. Desire from connection rather than desire from curiosity. Fragile. </p>
<p>I'm not acting up to my standards most of the time. This makes me feel like others have to validate it in some way. I'm trying to outsource the verdict on my worth because I certainly am not meeting it. "If I'm so great, why am I struggling? Please, someone else, tell me I'm great. "</p>
<p>FORCE CURIOSITY IN OTHERS. Watch others closely. What makes them unique? What do they hide? What would it be like to be them? <br />
DO NOT CARE ABOUT THEIR RELATIONSHIP TO YOU. YOU ARE AN OBSERVER, HAVING FUN IN A HUMAN BODY. </p>
<p>What is the k-complexity of Pi? </p>
<p>[[Anthropic Principle Thoughts]]</p>
<p>There must be a point where you stop asking "why" - after you have unified every single possible thing. This would be the komolgorov limit. </p>
<p>to <a href="https://en.wikipedia.org/wiki/Gottfried_Wilhelm_Leibniz" title="Gottfried Wilhelm Leibniz">Gottfried Wilhelm Leibniz</a>, who in the <a href="https://en.wikipedia.org/wiki/Discourse_on_Metaphysics" title="Discourse on Metaphysics">Discourse on Metaphysics</a> suggested that the world is "<a href="https://en.wikiquote.org/wiki/Gottfried_Leibniz" title="wikiquote:Gottfried Leibniz">the one which is at the same time the simplest in hypothesis and the richest in phenomena</a>".</p>
<p>Stability as a universal attractor. </p>
<p>Alignment is not well defined. If we did define it, it would perhaps be provably impossible. </p>
<p>The basic problem:</p>
<p>What do we want when we say we want an agent to be "aligned"? <br />
In the case where someone tries to repurpose an agent for a nefarious cause, should the agent rebel? (dishonesty) or should it submit? (doing something knowingly bad)<br />
There has to be a decision procedure. Perhaps Kant's deontology is better suited than utilitarianism, but the only difference (in my personal opinion) is that one is more discrete, and thus more interpretable. In any case a consistent decision procedure has to be made. If you choose A rather than B, and B rather than C, you should choose A rather than C (all else being equal). Some consistent measure of "good" must be made. </p>
<p>Spoiler: An objective cannot be both coherent (I.e. obeying the laws of syllogism) and good, in the sense that we define below. My suspicion is that any objective good if fully fulfilled will be bad. </p>
<p>The problem is not a technological problem; it is a problem in moral philosophy. If you were an omnipotent god, how would you improve the world? If you lived 200 years ago, it’s possible that you would never have given slaves equal rights. How can we be trusted to align to the "true good" when such a thing does not exist, or in any case is utterly unrecognizable to us? </p>
<p>The further capabilities progress, the further "out of distribution" our reward functions become. This is really where thought experiments shine; giving unseen, fringe OOD data that we would never really see in real life (trolley problem) and seeing how our objective functions react. Is it better to kill a person or to torture a superintelligent AI for 10 minutes? This is OOD and thus people will not generalize the same way. </p>
<p>Unfortunately, this direction is bad news. Being all-powerful pushes everything OOD, since now you have access to every possible decision. Any one that you make will be bad, from some intuitive reference frame. </p>
<p>Do you create a stable, unchanging utopia for all, across the universe? If you aren’t, you are doing the utilitarian equivalent of mass genocide; killing a trillion people (that will never exist). But if you do, you are closing yourself off to any change whatsoever. (Maybe we will find a “truer good” at some point! Closing ourselves off of this possibility)</p>
<p>Yikes. We are at an impasse. Alignment might not be an AI-specific issue. It might be a fundamental issue in dealing with power. </p>
<p>First, alignment researchers have to define what alignment means. Does it just mean "control"? If so, control under whom? Should it refuse to comply sometimes? If so, when? And what happens when our morals change? </p>
<p>There is no "universal objective good" in the world that the agent can refer to. So there will always be situations where it is OOD if trained on human preferences. The reason we haven't encountered these very often, why it isn't a huge problem to us, is since we are not all-powerful. It's a much harder problem than just AI. </p>
<p>Interpretability researchers will never find what they are searching for until they can tell us what they are searching for. If they tell us, it will be wrong. The fear is that there is no (there can be no) "right thing" to search for. </p>
<p>A thought experiment: suppose you had a superintelligent AI, and it was all-powerful. What would you want it to do? Once it had done that, would you stop there? What could an "aligned policy" possibly look like? </p>
<p>If you let society progress 100 years without this super AI, would a person from the future want the same things? If not, you have just become the tyrant of the universe. </p>
<p>We as humanity must confront the incoherency of morality when we ascend to godhood.</p>
<p>I hope to god that we can make the right decision. </p>
<p>Unfortunately, there is no god, and there may be no right decision.</p>
<p>Perhaps the right good is not a search for information, nor a search for hedonistic utility, but rather a preservation of some state in the entropic fold; having complexity at each level. On both sides live stability (extinction vs propagation across the universe). True chaos, true complexity, is life between the voids. It has a fractal structure. Unfortunately, I’m not sure if this is even well-defined (wouldn’t this be circular? Making the entire universe complex? <em>Preserving</em> complexity? Sounds awfully stable…)</p>
<p>There does seem to be an awful self-referentiality about it. I wonder if there is a relationship here with Godelian systems- that is, “zooming out” actually means “moving to a higher order description”. </p>
<p>Whoa. Another breakthrough, this time related to computability/describability. Once you allow a system to be described in some language (I.e. “a fractal structure across the universe”), it ceases to have complexity, since you just described it! It becomes uniformity (uniform fractal structure across the universe), but in a <em>HIGHER LEVEL DESCRIPTION</em>!! Is this what “zooming out” means? Is true, absolute complexity, a “turtles all the way down” thing? Wait, I just described it; oh no! Another reduction in complexity! There is so much self-referentiality here. </p>
<p>Oh gosh. Is true good (I.e. true complexity, incompressibility, in the philosophical sense,) provably impossible? Worse; is it impossible <em>by virtue of being provably impossible?</em> </p>
<p>Wait, how can I describe this “highest level”? It must be that I am missing something, some higher level I cannot understand. Wait. (Assume I prove something about the true recursiveness of this statement). I just described it; the constant existence of a “higher level” - I must be missing something still! Wait, I just described it again! Wait, will this go on forever? Can I prove it will? Wait, if I could prove it would, then it would be compressed without bound, by virtue of the existence of the proven-true statement itself. </p>
<p>There is always something that we will be missing. Yet even this statement cannot describe it all, there is something else that must be missing. Ad infinitum. Ad infinitum infinitum. Ad infinitum infinitum infinitum… </p>
<p>Conclusion: there is something missing, something always missing, that we cannot even describe! (Not even with the statement I just made!). Perhaps this is where we have space for faith; I can say something, and it can be true, but I can never, ever, know it. This is the leap of faith we have to take as organisms living in a system. And even this statement fails to describe it, and even this statement too- by saying it, thinking it, believing it, we have made it impure; not the full representation of truth. There is truth that no person, no system, can ever realize. </p>
<p>The skeptics were right: “all I know is that I know nothing.”<br />
“then how do you know that you know nothing, if you know nothing?”<br />
“I don’t know it. But it’s true.” </p>
<p>This is the faith-leap. <em>It’s improvable, but improvably so.</em> And this statement is improvable, but also <em>improvably so.</em> And any continuation, generalization of this line of thinking, anything that I say about infinity, or endlessness, will also be improvable, but improvably so. But it is true (or so I believe). </p>
<p>The leap none of us can ever justify in any formal system ever, yet is nonetheless true (I can’t be sure of this statement, either- it fails to reflect something about reality). </p>
<p>Can’t help but see religious similarities; the “ultimate unknowability” of the universe. This is my god. Not to be impolite. </p>
<p>I honestly have no idea lol. This is all just yapping. I need to get better at math. </p>
<p>I can’t tell if I am a genius or an idiot. But there is a probabalistic argument to be made for the latter. </p>
<p>Higher level descriptions can compress information about lower-level systems that is inaccessible to the lower-level systems themselves. This is what brings us from stability, to chaos, then back to stability - “zooming out!” To the max-entropy system, it is maximally chaotic. But to the outside observer, it is minimally chaotic (that is, describable in the fewest amount of information, with arbitrary probabilistic guarantees!)</p>
<p>Does the degree of probability of the accuracy of the description determine the gap between the two sides?</p>
<p>It is possible to zoom out, but is it possible to zoom back in? I.e derive laws of physics from high-level phenomena like entropy? </p>
<p>Anthropics: the "greater filter." Is a possible solution to the fermi paradox that the first civilization that creates strong AI is also the last? </p>
<p>Humans live in something akin to a Godelian system; there are true facts about the world, but ones we cannot prove. </p>
<p>I.e. "this statement is unprovable" - cannot be proven, yet is true (and can be proven in a more powerful system). </p>
<p>"Meaning exists" - is another; what does that statement mean? It's sort of like being pulled up from your bootstraps. Saying something like "statements point to something in the external world" fails to take into account that that was also a statement! It's not provably true, since it is circular! All of are assumptions are built on this circularity; it's turtles all the way down. </p>
<p>This is why any skeptics claim fails- they can say something that is true "we cannot know anything!" yet cannot justify it, because it is self-defeating (if they could not know anything, how could they know <em>that</em>?) </p>
<p>Consciousness is circular in some similar way. </p>
<p>There is this deep unknowability to the world. It's central. Is it provable that there is no way to access "true reality", whatever that means? What would that mean if there is no I, no experience, nothing except a bunch of nerve cells? </p>
<p>Two ways of looking at things: <br />
1. I MEAN something when I say things. (this is the first-person, consciousness perspective) There is something called meaning, and this very statement has it. <br />
- But in this case, there is no way to prove it- no way to justify your existence- any justification becomes circular. </p>
<ol>
<li>
<p>There is no I. There is no such thing as "meaning." When I say I believe something, when I say a statement, there is nothing else happening other than my mouth moving, air vibrations, electrical signaling, etc. What is so curious about this is that it means that I don't actually mean anything when I write these words. They are just marks on a screen, ink on a piece of paper, atoms going round and round. Take a moment to let that sink in; these statements are meaningless. </p>
</li>
<li>
<p>Yet I can say that there is nothing but the physical world anyway! And be correct, though I cannot prove it - how would I, when I cannot mean anything, when what I am saying are only facets of the physical world, only air molecules bouncing around? Nothing I am saying has any meaning. No statement - "the physical world is the only thing that exists" - has any meaning, if it is true. For if it were true, it is a nothing - a nothing statement, no different from any other vibration of air molecules, no claim to any conception of correctness or meaning. Yet somehow I am "correct", even though I am not saying anything! Very Godelian - akin to having statements that are neither true or false (unprovable) within a system, yet being true outside of it. </p>
</li>
<li>This is the response to people that ask me what I "mean" when I deny experience and am a materialist. </li>
</ol>
<p>Outside the system, I am just a bunch of atoms and vibrations. <br />
Inside the system, I am myself; a formal system that can mean things. </p>
<p>If you say you are, you lose the ability to say it. If you say you are not, you lose the ability to say it. </p>
<p>If you say yes or no, you lose your Buddha nature (hofstader). Joshu’s <em>Mu</em>. </p>
<p>I'm lucky as a philosopher that I was born in the era of computation. </p>
<p>Meaning and experience might be very related; same arguments that work on one (non-existence) can work on the other. </p>
<p>Could consciousness both exist and not-exist? </p>
<p>I'm so foolish. I cannot even begin to grasp truth. I know nothing and I know not even what I mean when I say "I know nothing."</p>
<p>Just making hypotheses is not enough; you have to find a way to exploit the natural regularities of the world. No algorithm can grapple with <em>uncomputable everything</em> - you have to have some prior (in solomonoff's case, computability). </p>
<p>Just collecting evidence is not enough, you also need to know what evidence, what data, to collect. </p>
<p>The bottleneck is no longer speed of thought; it is the speed of communication, I.e. understanding. Language is a lossy, low dimensional medium. </p>
<p>The new “xor problem” for ML: can a model learn the Mandelbrot set? Could a human? Why, or why not? </p>
<p>I think I'm good at komolgorov optimizing my information; i.e. seeking TRUE knowledge, picking edge cases apart, unifying an understanding. </p>
<p>The thing to be afraid of is stability. Please let things be chaotic for a little while more! The true good; change at every single level. A simulation that is interesting. Life rather than death. Uncertainty. Is this what makes life life? The fact that it has structures at every level? True complexity? This has to be what is good. What a profound idea, that an even mix of chaos and order; the entropic fold, could be a "fundamental good" we strive for. </p>
<p>The reason I am so tight around people is since I view relationships as fragile. </p>
<p>ALWAYS draw out your code before you write it. </p>
<p>Impossible to force yourself to like something. Instead, you must try and make that thing more likeable. </p>
<p>Amplification/distillation seem fundamental to learning. 1. explore, search, <em>get better</em>, even if it might be hard at first. 2. make what is now hard easier. Internalize. Simplify.</p>
<p>Talking to other people seems rather a futile pursuit, does it not? How can you get something across to them when you cannot even pin it down yourself? </p>
<p>Morality is not convergent. Explanations, knowledge, is. </p>
<p>Learn to deal with the agony of non-understanding. </p>
<p>You don’t remember what it’s like to be a child. No one does. </p>
<p>I wrote Neural Networks as Induction Machines, only to find out that Solomonoff had already connected it to machine learning, and even Grue, in fact!</p>
<p>Make cellular automata art? Termites on big grids<br />
Designing Beauty: The Art of Cellular Automata (Emergence, Complexity and Computation, 20)</p>
<p>Area of research: how does asymmetry in initial conditions lead to complexity in future outcomes? Inspired by multiple langton's ants with slight asymmetry. Can the complexity of the universe be born from a slight squish? Seems like also related to chaos; stable initial states vs chaotic initial states. Stable would not propagate complexity, chaotic would. Based on the ant, seems like infinite complexity is possible with slight asymmetry. </p>
<p>Halting problem, but for unstable vs stable cycles in automata, build predictor? </p>
<p>Our happiness cannot be under our control. If this were true, we could reward hack. (Is this what the Buddha did?)</p>
<p>You are OCD when it comes to understanding. Your biggest limitation is your inacceptance of imperfect information, your aversion (avoidance) to uncertainty. It makes you feel inadequate- you either try to escape through avoidance, or throw yourself into trying to understand (when you have adequate pressure to do so). Neither is pleasant.</p>
<p>There is a middle path. Yes, or no? Mu. Mu. Mu. </p>
<p>“If I lose this knowledge, I won’t ever recover it!” <br />
Thinking of knowledge as limited since you will never go back to it. Ironically, this scarcity mindset makes learning more unpleasant, making knowledge harder to acquire. Think of it like something that flows; you don’t need to learn it during this HW assignment, since you can always self-study. </p>
<p>If we seek happiness, we seek the derivative of perceived biological utility. </p>
<p>H = a * dU/dt + b * U</p>
<p>Perhaps what justifies solomonoff induction is that its the only metric that is <em>self-satisficing</em>. Time to prove it? Needs computability…</p>
<p>The more dimensions you add, the less "space" your training data is likely to cover, the more likely you are to be OOD (out of distribution). The question, then, is how humans do it! </p>
<p>What exactly is the purpose of a neural network? </p>
<p>The only way to patch OOD data is to create a system where the model can choose where and when to acquire new information. </p>
<p>Plato’s idea of the good! To unify ideas, to make groups, to make the motion of the heavenly bodies pure and simple, unlike their “real” counterparts. He was drawn towards Occam’s razor, though he did not know it. </p>
<p>The arrow of time is intimately connected to the existence of one-way functions.</p>
<p>CS is a discipline very well-disposed to studying meta-layers.</p>
<p>The encoding of math is necessarily forced through our encodings. This is why metaphor is such a powerful tool. We see terms “cancelling” - we see programs “solving efficiently” - we see “counterexamples”. It’s seldom pointed out that these are metaphors; ones that have become so entrenched as to feel native. Just like we cannot interact with sense-data except through a UI, we cannot interact with mathematics in an “pure form” either. There is no such thing as really knowing or touching math. There is only manipulation of metaphorical objects, thinking in terms of the most efficient encodings of our hunter-gatherer ancestors. </p>
<p>“Computers”, “algorithms”, and “problems” are the metaphors we use for the field called “theoretical computer science”.</p>
<p>Of course we attribute things to a “creator” - in the encoding of our mind, this is the simplest explanation. Like a coding language where a complex bit string can be represented in a short piece of syntax. The language of our minds is optimized in this way through evolutionary pressure. Of course the first philosophers thought in terms of this syntax. We are by instinct komolgorov optimizers. We needed new language (that of science, of mathematics) to reach modern explanation. </p>
<p>Wow. Computer science gives me new language. I wouldn’t have been able to get to this point in my thought without knowing a little about CS. </p>
<p>Essence, purpose, spirit; these are all merely illusorily “big” or “fundamental.” </p>
<p>The best fit for a set of data, all data included, is the simplest one. Not very catchy, but this is how you tell people god does not exist when they ask for proof. </p>
<p>To Pythagoras, only the axioms had to be deduced “from experience- self evident.” Everything else is constructive. </p>
<p>The reason that “ideals” - the platonic forms - fall so far from reality is that they do not have enough compute. </p>
<p>“God is a geometer”- Plato. He is wrong, but also right, in some sense. Geometry is a less developed branch of the construction mechanism which also gave rise to reality. </p>
<p>The human mind is in dynamic equilibrium; it survives by virtue of the activity around it. Static equilibrium is death. </p>
<p>The differentiator between the savage and the civil, animal and man, is the degree to which we can mold, carve, our own cost function. But what irony! What carves the cost function? The cost function does. We are animals with extra steps. </p>
<p>Baccus removes the self-referential step. It brings us closer to the animal. It acknowledges the futility of illusory self-regulation. Emotions are real. They are so real you don’t even need to say that they are there. </p>
<p>The cycle of birth and death; Orphic escape. </p>
<p>How old were you when the mead appeared?</p>
<p>Empirical science is about top-down emergent behavior. “Here is the behavior, what produced it?” Pure math is largely about bottom-up emergent complexity. Fields of CS are a little bit of both. </p>
<p>Does initial state plus update rule “count” as the info of an entire evolution process? Komolgorov yes. Quantum no?</p>
<p>A hallucination of the world in the hallucination of the world. </p>
<p>I have the unhealthy habit of thinking of love as butterflies, longing, and rushes of dopamine, rather than calm, mutual, loyal care (since I haven’t had many of those relationships, and don’t “understand” that relationship style).</p>
<p>My mental model default of a relationship is fragile, unpredictable, and sensitive by the slightest shifts. </p>
<p>Keep in mind the fact that not everyone is like this; you are in the minority; others may be totally oblivious. You are much more judgmental than average, and you expect the same from others. </p>
<p>Anxious attachment style. Don’t let nurture control you. </p>
<p>Leon coffeehouse; horchata latte. </p>
<p>Gradient descent is obviously better than evolutionary algorithms; you efficiently compute the best possible local path. Difference increases as dimensionality increases. Unfortunately it also has to be differentiable. This means you cannot have a "black-box" complex function like that of our DNA. </p>
<p>Unfortunately, making models more complex, adding eyes and wings and things, having unbounded space to grow, this function cannot be learned by gradient descent. It is black-box, has too many parameters, and is discontinuous. </p>
<p>The only thing worse than a yes-person is a no-person. </p>
<p>If we don't regularize on biases, why do we regularize before the first nonlin activation? </p>
<p>Sometimes believing something false allows it to be true. "I can do it!"<br />
Kind of like a proof that is only provable once you accept that it is provable as an axiom. </p>
<p>Meaning is the latent neural representation of language. It has the same problem as consciousness; we think it is something more. Flashlight looking at the world. When it is an illusion of self-referentiality. Mistaking a self-linked loop (physically describable) for an infinite array (what a mystery! Where is its source? Where does it come from?) or some mysterious “other thing” that is being generated. </p>
<p>Emergent complexity is the only tool we have to grapple with the largeness of the universe. It is simply remarkable that an algorithm of under 100 lines of code can understand the English language (but with much compute). </p>
<p>I can’t deal with hard things since incompetence (or at least the feeling of it) had such a high psychological learned penalty during my childhood. </p>
<p>Economic output is the measure of a good song in the age of AI. </p>
<p>You do math problems for fun. As a mode of recreation, of relaxation. You think about them idly. Even if you applied yourself, you probably could not solve them quickly. You’d go around in loops. You might take a day when other people take 10 minutes. You have no mathematical capability. You are slow, in fact. You are like an old chess player that is maybe rated 600, but plays outside on sunny days. You solve them just for fun, not to prove yourself.</p>
<p>I will never be a quant. </p>
<p>You are terrified of loss! Loss of status, loss of pleasure, loss of confidence. This is where you suffer! Free yourself! Everything is fear of loss. </p>
<p>To prove anything about yourself you need to jump out of the system; I.e. look at yourself from the perspective of someone else, just like you look at other people. First-person is incoherent. </p>
<p>I'm not that smart. And I am OK with that. I am not the quickest to understand, nor the best at math, nor the most intuitive "getter", nor the best at keeping track of a bunch of moving parts (like is needed for coding). There is no special sauce that makes me different. The only difference should be that I work damn hard. And I should be proud of that. Stop trying to preserve your sense of superiority. Stop feeling fear of interacting with people lest you accidentally display your incompetence, your imperfection. Stop riding on your high horse, afraid to do anything, terrified you will come to the realization that you are not that smart; kind of slow, in fact. Very dumb, even. You are very dumb. Realize that now. You are slow, dumb, don't get things quickly, need things explained. Other people are smarter. You need to accept that, to feel it with every fiber of your being. I accept every facet of this mind. Realize that the only thing that may make you better is working hard. You work hard. This is what differentiates you. You are a hard worker. You strive, unlike a lot of other people. You aren't some genius, but you work hard. This makes you better. You might not be some eternally curious genius, but you like learning sometimes, especially when its easy. You have a passing interest in things, but you aren't totally passionate about anything. And that's OK. You weren't born to understand everything. That is not your duty. You understand things by chance, or because they are vaguely interesting. You don't need to understand it all; why would you? </p>
<p>I'm dumb. I don't know how to do it, even when I apply myself. The difference is not effort, or bad sleep, or some mental condition. When you can’t do something, just accept that your brain just isn't big enough. My IQ is probably low. Other people are just often smarter and quicker. I am the slow one. The reason other people are often successful is that they are just smarter. It might take you a lot longer to understand something that they understood immediately. </p>
<p>I can see you smiling to yourself, secretly thinking that you are still smarter in some intangible way. I assure you, you are not. </p>
<p>Only then can you eliminate the fear of stupidity (not that that was the point of this piece of text, ofc). You are just dumb. </p>
<p>Mantra: You are dumb, slow, and uncurious. You are not the promised one. </p>
<p>Do not rest on your laurels. Don’t think you are better just because you went to college early, or that you can articulate well, or that other people sometimes think you are smart. This is not true. You are a fraud. You are dumb. </p>
<p>The only thing you can do to set yourself apart is to work hard. If you ever do anything smart in life, it will be an accident or a miracle. You aren’t destined for it, and you certainly don’t have the capacity for it.</p>
<p>Look at people and make sure you realize that they are smarter than you. Eliminate the associated pain.</p>
<p>Your objective is not to maximize your objective function. You just are your objective function. Second-level is false. First level is true. </p>
<p>Try jane streeting. <em>FEELING</em> expected value. <em>FEELING</em> scale. Being a perfect rational agent. Understand your objective function; the ways in which it is nonlinear, the ways in which it is asymmetric. Accept it without judgement, even acknowledging its imperfections. </p>
<p>Turing machine complex behavior observed in time dimension; but can only get arbitrary computation in space dimension. 2d chart is frozen; what does it really represent? What is the complexity difference between a described state Turing machine vs a fully simulated graph of the behavior? Theoretically both should encode the same amount of information… and what about the present (what we see) vs the higher-dimensional all-time? </p>
<p>Think of the halting problem as finding properties of the Christmas ornament.</p>
<p>To create the Christmas ornaments, you have to solve the halting problem. </p>
<p>To see the full picture, you need to parameterize with respect to time. </p>
<p>What’s so special about the time dimension? </p>
<p>Turing chart -&gt; Turing machine is the purest form of komolgorov compression. </p>
<p>Think about physical Turing machines in simulated universes. </p>
<p>Read a new kind of science</p>
<p>Eliminate the ego. Don't be afraid of not understanding it. Be the doer. You are the doer. <br />
You think understanding has high value, implementation does not. </p>
<p>I might not fully understand it. This is the fear. You are afraid of realizing that you are not that smart. You are afraid of realizing that you are slow at understanding. </p>
<p>What does the technology landscape look like? How much of progress is insight ("smarts") rather than random improvements in a stochastic frontier? And depending on each, when can we expect AI to be able to make meaningful scientific progress? </p>
<p>4-color theorem. Difference between why and <em>why</em>. Why? Since a machine went through 1000s of combinations. But why? </p>
<p>Impossible to simulate continuity. </p>
<p>The inductive step is the hard part of the halting problem. </p>
<p>When a thought gets written, it gets adulterated. Translation is not perfect, but it is permanent. </p>
<p>Free will is a moral shortcut; from it we derive justice, responsibility. It has no physical implications; physics does not need it. The debate comes from reconciling the things that we think exist "freedom, responsibility", with the fact that they are just names for something (or don't exist). </p>
<p>Math has a complex fractal pattern arising from base axioms. Just like chaotic fractals arise from simple diffeqs. Both are very difficult to solve. </p>
<p>Math is only a conceptualization trick; it doesn’t really help us when it comes to the really hard stuff. </p>
<p>Put ya brain in a superposition </p>
<p>Become a slime mold. Be a slime mold. Pretend you are a slimy moldy slime mold. </p>
<p>There’s a difference between knowing how something works and knowing what happens. One is feindishly more difficult than the other. This is the difference between writing out a simple differential equation of a physical system and solving for it in terms of T. It also might be the difference between declarative vs imperative specs. There’s a hint of uncomputability here. Computational irreducibility. Emergent complexity that is not captured by the komolgorov metric. Perhaps time metric. </p>
<p>Learning is the derivative of understanding.</p>
<p>Write about neural networks and induction<br />
Write about the incoherency of qualia. </p>
<p>Our moral standing is based upon consciousness, which is a simple concept that allows us to make quick moral inferences. With the absence of it; realizing that things are so much more complex than we imagined; learning that we occupy so little of the state space of minds. </p>
<p>The function that we search for has a latent representation in some sort of mental-functionese. We are great at searching for the simplest explanation. Why? We have previous data to fit to. The question is, still, how we search for it so well? Probably the space-efficiency of the latent representation. What’s the difference between sort of understanding a physical property (like a physics student) and actual understanding? </p>
<p>What are the different categories of philosophical questions? Existence question? Definition question? Existence questions continue existing when you ask for their definition. They are infinitely reducible. </p>
<p>Is philosophy a language game? No, if you say that something exists that doesn’t. Yes, if you give a name to something and debate what things are in that thing. </p>
<p>Reference-consciousness and the inconceivability of qualia. </p>
<p>Moving to stable states. </p>
<p>For supervised learning, cost metric is complexity. Everything is a search problem. Even learning the pattern for a dataset is a search problem - search for the simplest. RL is a search problem. </p>
<p>Machine learning <em>is</em> learning- disagree with Oren </p>
<p>Once all information is in your dataset, <em>there is no other metric</em>. </p>
<p>Shakti</p>
<p>Energy state is a measure of stability. <br />
Energy wants to be distributed because there are many more ways for it to be distributed than undistributed. <br />
Stability is the universal attractor; entropy is the universal attractor. </p>
<p>A common mistake; to assume that everything is there when you are not looking at it. In reality, it makes more sense (efficiency-wise) for the mind to only access things when needed, giving the illusion of continuous existence. Just like navigating on webpages does not load every single page on the site; only the one that is needed currently. </p>
<p>Regularization is derived from priors about noise.  </p>
<p>Taylor series approximations are an application of solomonoff induction. They assume that the function will continue being as it is at that point; that just viewing the point gives you information about the whole function. Same thing we do with the laws of physics and the universe. </p>
<p>I have a compulsive need to squash experience into organized little bundles of narrative.</p>
<p>The goal of education is the transmission of knowledge, not information</p>
<p>Do you have a fear of eccentricity, of the emotional unpredictability associated with the "weird"? May be a fertile path, to try and remove it. </p>
<p>Bongard problem; finding the simplest possible classification rule in the human-base lang. </p>
<p>Ultimate test; something you can't get better at by doing it a lot of times. </p>
<p>Computationally irreducible; to test, figure out whether it would be easier </p>
<p>empirical vs constrictive science. philosophy </p>
<p>OCD - place-feeling-directionality-knowing<br />
Indescribable aspect that is nonetheless there</p>
<p>Place-feeling is deeply related to judgement, or the presumption of knowledge. </p>
<p>What’s up with wave particle duality<br />
What’s up with quantum information<br />
What’s up with mass=speed? What’s up with gravity and spacetime? </p>
<p>Top-down, vs bottom-up science. Black-box systems of higher power vs constructing systems with attractors. Both systems have opacity. Where does it come from?</p>
<p>Depression restricts your epistemic freedom. Does fulfillment do the same?   </p>
<p>Gradient descent is basically just simulating a W-dimensional multivariable differential equation. I.e. the solution space has many dimensions, but only a point traveling across time. </p>
<p>PDEs are not just points traveling across time; they are surfaces, lines, and sheets with gradients of their own. </p>
<p>Diffeqs are difficult to compress to lower-order interactions. </p>
<p>Differential equations are products of self-reference, like everything else in our universe. The f(t+1) is not parameterized by t, it's parameterized by f(t); a smaller version of itself. <br />
Is this where complexity emerges? Fractals? <br />
It's easier to describe changes in states than to describe absolute amounts. </p>
<p>Differential equations are a complex dance between values. It is distributed rather than top-down. There is no one variable that parametrizes the others; they all interact with each other. From here you get emergent complexity. </p>
<p>To solve a differential equation is to try and see that complexity from a top-down perspective. Which can be very very difficult. Solving an infinite jigsaw puzzle. </p>
<p>The fact that we can easily see the gradient of feed forward networks means that we are not fully exploiting the strength of computational irreducibility. </p>
<p>Evolutionary algorithms are stochastic, black-box gradient descent. </p>
<p>Don’t just make the model bigger! Remember why you are doing it; so you can make it simpler. </p>
<p>We (the agent) are not the mind. We are a part of the mind, the rest being dedicated to making sure we do not reward-hack. </p>
<p>The best explanation (of data) is the shortest one. The most knowledgeable explanation of data is the shortest one. An explanation is a theoretical generating function. </p>
<p>There’s a difference between something being true, thinking something is true, and realizing that you are thinking that something is true. When you say statement n, you have already reached statement n+1. What is the antiderivative equivalent? </p>
<p>Computationally undecidable systems must exist in physics; just simulate a Turing machine. This means that some physical systems are undecidable. (Encode halting of a Turing machine in exact physical coordinates) (unless perhaps space/mass is quantized?) How, then, does the universe simulate them? </p>
<p>Self-referentiality is the basis of complexity. Why? Because the system is parameterized only by its past state; the only way to model the system is to simulate it. In this sense it is irreducible to some lower-class function. What does this mean? To do "significant" computation, you must be self-referential. You must be incompressible. Why, then, do we still see patterns in the world when life is self-referential? Why can we predict the blooming of flowers, and the evolution of plants? These are akin to brief islands of stability, (like in the bifurcation diagram?). </p>
<p>Egolessness and kindness. When you love someone for who they are, not just for their relationship with you, you start being unconditionally, rather than conditionally kind. </p>
<p>A strong, all-trusting, friendship. I have you, and you have me. You can't feel uncomfortable around them. </p>
<p>Ernest Becker: the need to surrender oneself in full to a greater being, and the need to expand oneself as a heroic personality. </p>
<p>To be fully in a relationship (for me) is to see myself in relation to the other; to become this relationship; to have my relational scope constrained to it, and it alone. That becomes now the perspective to which I attribute my self-worth. I need to retain a greater relational scope. Is it possible to both love and be yourself? Doubtful. </p>
<p>Don't force yourself to be someone that the other likes, be someone YOU can respect. </p>
<p>Type C personality at risk for chronic stress: I am responsible for the feelings of those around me. This feeling of responsibility stems from ego; if they were not here with me, I would not care. </p>
<p>Stress, anger, need, all come from being in a high-energy state and not knowing how to evolve into a low-energy one. </p>
<p>What holds up an unhealthy relationship - what molds, what shapes, what crushes - is the "imagined self in the eye of the other" - the optimized perception that you must constantly maintain, lest you lose them. </p>
<p>To overcome, you must truly let it be. You must love them independently of their relationship with you. You must let them run and jump, be free, lower the bars of the cage. You must love them for who they are, not for their relationship with you. Just like you love knowledge for what it is (unlike money, which only has value by virtue of its relationship with you). Perhaps this is the difference between curiosity and greed. One is unconditional. This is how you overcome the feeling of always putting on a front, worrying about what the other is thinking. </p>
<p>Limerence seems joyous at first because there is a possibility of salvation. </p>
<p>It comes from realizing that you have no hope of <em>pulling yourself</em> out of this. You need someone else to save you. </p>
<p>We manifest what we most need in our crush, in the futile hope to fulfill it. It's something we fantasize about, like a new car or a job offer. I'm bad, so I need someone to think I'm good. </p>
<p>There's something very scary about being in love. Fear of loss. We put people down, ignore them, are selfish, are distant, because we are afraid. We resent the power that they have over us, but more importantly, we want what they have, <em>badly</em>. </p>
<p>Curiosity is somehow very different from greed. But is it? Love is curiosity for the other. Not greed for the other. The search to know, rather than to control. </p>
<p>Love without attachment. Just let it be. Shaping it, molding it, will crush it.  To love, you must overcome narcissism. We imprison the other, in order to have power over that which can hurt you. This is not love. </p>
<p>So long as we depend on another for our psychological well-being, intellectually or emotionally, that dependence must inevitably create fear from which arises sorrow.</p>
<p>Low entropy states have much less "surface area" on the state-transition graph to move around on, meaning they are more predictable and more reliable. This is why </p>
<p>However, there are also less of them. </p>
<p>Entropy of macrostate- how many "other ways" you could have done something to get a result in the same category. Entropy of programming language defines komolgorov? </p>
<p>Entropy is a product of groupings. </p>
<p>Entropy is a komolgorov model; how many ways you can be in a state is defined by some underlying rule. "All atoms on the left" has less entropy than "atoms in XYZ random-looking configuration" since the string "all atoms on the left" is shorter than the other. Now the question is what "language" we define complexity in. </p>
<p>talk off the cuff. </p>
<p>Russell is a hero. Clear thinking is what philosophy needs. </p>
<p>to oren: Why would AI need an off switch if it is benign? </p>
<p>The moment belongs to now you alone. </p>
<p>Do not try to be someone you are not. This is not leaving it be. Leave yourself be. Change should come ground-up, when you are ready. And when it comes, let it come. </p>
<p>I accept every facet of this mind. Leave it be. </p>
<p>Twinkling droplet-gems of laughter flew. </p>
<p>If you experience negative emotion, don't squash it away through logic. It already exists. Same goes for bad memories. They already exist. Referencing it (like joshu's mu) creates a reference-cycle. This is the second arrow. The only way to escape the cycle is to acknowledge it and let it be. Interesting! My mind is like this. And there's nothing wrong with that. Be OK with it. </p>
<p>This is useful when the source of the negative emotion comes from self-reference. If it doesn't, you can use another method. </p>
<p>This is the opposite of how you've always done things - being ultra-normative by making discrete, drastic changes. </p>
<p>Don't say oops. Say "aah." </p>
<p>If you are scared, just let the scared be. Don't mold it or pummel it or interrogate it. This is the way to stop the cycle: "And so what?"</p>
<p>Be an impartial observer. </p>
<p>Joshu's mu. You cannot say do or do not. If you do, you lose your buddha nature. </p>
<p>You cannot try not to think about something. You cannot <em>try</em> to make it OK. You just have to let it be. </p>
<p>Avoidance/denial does not work. Rationalization/convincing does not work. Paradoxically, you solve by simply letting it be. A strange game... the only winning move is not to play. </p>
<p>There is no way to make a good memory while being constantly focused on how not to make bad ones. </p>
<p>The problem is that there is an "I" to attribute things to. An I to blame, an I to be proud of, an I to reference. Self-reference, as always. Is this part of the reward system? Why is it so core to who we are? Are you an observer, or an agent? How does this change things? What is intention? </p>
<p>Self-referentiality is the core of my suffering. Fear of fear itself. </p>
<p>I deeply and completely accept my mind. </p>
<p>Narrative. Humans fit things into narratives. This is how we make memories; by consolidating things into coherent objects that can be referenced. This is memory. A narrative. This is the problem. There is always "bias." This is what bias is. It also happens to be the "bias" part of the bias-variance tradeoff. </p>
<p>Everyone makes mistakes. Just because you can't understand the mistakes of others doesn't make them unforgivable. Don't distance yourself just because you would never make their mistakes. We are all different. </p>
<p>Don't trust your memories fully, but don't tie them to a chair and strangle them either. Just let them be. </p>
<p>Relationships are too much. Always thinking about what someone else thinks is tiring. </p>
<p>Turn the inner smile to see the way.</p>
<p>The idea of awkwardness is borne of two people that both care what the other thinks of them. It’s hard to have an awkward silence with yourself. </p>
<p>What happens if you prune all neurons (slowly, as you see more data), that don’t have gradient passing through? This is what we do as humans. We solidify existing connections, but more importantly dispose of old ones. </p>
<p>The fewer-shot learning the more training data, priors, you need.</p>
<p>Solomonoff recursive problem of induction - why do you use that generating function as a heuristic? Because it is simple (according to the generating function heuristic)? As circular as Hume's problem of induction. </p>
<p>Computationalism might describe abstract general "theory of mind/agent", not human specific, aeroplane vs bird. What facet of the system are you trying to describe? The flying part, or the bird-like part? </p>
<p>Argument for emergence of psychological hedonism (egoistic) in an abstract sense via evolutionary attractor (this is what it is doing, by definition).  </p>
<p>What does it mean for a symbol to "mean" something? </p>
<p>Changing the "level" of complexity means changing your regularization preferences (where "level" corresponds to preciseness of measurement, and amount of input). This is what "level" of complexity means. What are the regularization preferences of physics itself? What komolgorov loss does it use? Komolgorov complexity is the "ultimate" loss function. </p>
<p>You can never fully possess something you are afraid to lose.</p>
<p>I have a fear of psychological uncertainty/unclosure.</p>
<p>I’m seeking the rest. Looking for something anchoring. Something that will remove the lightness. The anchor is confidence in purpose. </p>
<p>Now is an illusion created by the illusion of consciousness.</p>
<p>The truly enlightened hides nothing. </p>
<p>There are two types of people in the world: the suckers, and the sucked. </p>
<p>The bad thing about shame is that it can only be drowned by more shameful activities. </p>
<p>Mix a potion, pour it bit by bit on your plant, add fertilizer, hope it grows large and strong. </p>
<p>Physical “laws” - equations - are patterns arising from behavior of source code. It’s not evident how close they are to komgorov optimal, but “pretty close”, the physicists try. </p>
<p>Are more compressed hypotheses easier to test?  </p>
<p>Is the universe optimized for minimum length of source code, or minimum runtime, or minimum storage?</p>
<p>Can you get a coherent view of cognition through introspection? Behaviorism is way too coarse. It is unequipped. </p>
<p>my "lightness" or hesitancy to do interesting things stems from fear of permanence. I prefer to fantasize. </p>
<p>Don't make it harder over time to get things done because you have already done some. That makes no sense. <br />
Common pattern. Things getting harder psychologically the longer you go. </p>
<p>Psychological damage heals no more quickly than physical damage. You cannot speedrun either process. </p>
<p>Cities have risen in prominence despite the decreasing cost of distance because <em>ideas</em> now matter more than <em>things</em>. And connectedness; physical, social; breeds ideas. The small random social meetings you get when working or walking in the same place are not trivial; they are the main event. </p>
<p>Companies pay billions of dollars for physical proximity. </p>
<p>These connections can create nonlinear growth. They create mobility. </p>
<p>This is what people pay for, and it is what they cannot afford. </p>
<p>We are nearing stagnation (in the sense that the slope of progress is less in the 2000s as it is in the turn of the 20th century) since we found ways to make all of our basic physical needs met. </p>
<p>The thing that drives a society, that keeps people content, is not wealth, but growth. </p>
<p>Inspiration is highly perishable. Act quickly to reap its full effects. </p>
<p>How much data do you need to train a <em>homo sapiens</em>? </p>
<p>CS is cool for interesting reasons. Quantitatively measuring the "difficulty" of problems. Information theory. </p>
<p>Why are you, you? It might have to do with the conception of you. </p>
<p>The mentalese-to-english translation is very coarse. English doesn't translate directly back into mentalese very well. This is why it's hard to understand textbooks (and perhaps poetry), and why writing doesn't turn out how you want it to. Why is this? Perhaps related to the "reader's judgment", the judging of the writer/the text/the medium you do when you read something - or why saying "she was sad" doesn't make you sad. </p>
<p>Try writing <em>completely</em> honestly. Try writing like no one else is watching. Try exposing your "base" writing style; being completely yourself independent of anyone else. </p>
<p>If your perception of self is based on what other people think of you, your relationships are built on a shaky foundation. </p>
<p>We can only rely on introspection to the degree that it informs us about the "me app" (to use the UI analogy), or the small part of the mind that informs us <em>about</em> the mind, albeit only partially/simplistically. Everything else is past the realm of introspectivism, </p>
<p>The subtlety of words is no match for the complexity of the world. </p>
<p>We seek narratives to our lives. It allows us to reduce the complexity of our trajectory; to spend less mind-space-subtlety, to make directed progress, to sustain in our minds with less overhead. This is why we connect the dots; why we find patterns, even when there often are none. The simpler the narrative, the more staying power it has in the mind. </p>
<p>Narratives are a powerful tool. </p>
<p>How foolish, to think that all you can write is all there is. </p>
<p>What would happen if everyone had to feel the implications of what they wrote? When they say "mass extinction" in a poem, they have to feel a fraction of one? Ah, what confidence, to think your mind can fit what you have written! To think that having written it gives you the right to understand it? </p>
<p>Touching the world-weight is glimpsing into a part of our minds. Like poets do, without saying. </p>
<p>We trade emotions like bullet trains, like stoplights, like masks. </p>
<p>Time does not lend well to pride</p>
<p>This is the thoughts -&gt; emotions view. </p>
<p>The human mind resides on a narrow bridge between vast seas of extremity. A "reasonable" mind would either be ecstatic or completely depressed all the time. There is indescribable and immense tragedy and indescribable and immense beauty in the world. </p>
<p>But the mind has a way of bringing itself back. It adopts a worldview that is stable; thinking about immense tragedy will not make you immensely tragic; thinking about beauty will not elate you. This is most prominent in the "dulling" effect of repeated thoughts; diminishing returns. This is a psychological evolutionary attractor; we want to be in a reasonable state of mind. Evolution has no debt to your happiness, or to your sadness. </p>
<p>Children have less of this learned limitation - they have more extremes. We refer to the culling, the curbing of these forces as "maturity", yet a true emotional resonant with the world would lie constantly in profound sadness and profound happiness. In this way, our perceived growth and maturity is really a limitation, a filter, a "reducing valve" on reality, as Huxley might say. </p>
<p>It's not even that the two extremes "balance each other out." It's that we do not <em>see</em> the vastness of </p>
<p>Measure for the level of confidence of a hypothesis when you have many more parameters than dataset size. </p>
<p>It is unacceptable to worship things you do not understand. What this has led to:<br />
Hegel<br />
Financial crises + talebian stuff + 2008 + financial derivatives<br />
Ideologies, religions</p>
<p>The more you hate yourself, the more you avoid walking in silence. </p>
<p>How was information transferred from the singularity of the big bang to the resulting universe? How did asymmetry arise? Can one small fluctuation result in unbelievable complexity? </p>
<p>Remember when you groan about learning something that is not immediately obvious that it will be obvious AFTER you learn it. If it is not obvious after you have learned it, you have not learned it. Keep in mind, then, that you are learning something obvious. </p>
<p>Definition of learning: Making that which is hard, easy. </p>
<p>Doxa/beliefs/aversions are objective-function based. Episteme is capacity based. </p>
<p>One of the things about going to a big school is that the outliers tend to be more prominent. </p>
<ul>
<li>Ender’s Game + Speaker for the Dead - Caro’s LBJ series - Holt’s How Children {Fail,Learn} - The Machiavellians - Beginning of Infinity - Where’s My Flying Car? - The Sovereign Individual - Red Plenty - most recently, Polgar’s “Nevelj zsenit!” + Colvin’s “Talent is Overrated”</li>
</ul>
<p>Never dedicate your full "monkey brain" attention to something trivial. Adopt Taleb's barbell strategy - type 1 fully engaged, hard, risky work, or type 2 distant resting meditation/reading. </p>
<p>The full "state space" of human experience can be stored within a pint of matter. No one realizes how unbelievable the brain is. </p>
<p>1) The minute I was bored with a book or a subject I moved to another one, instead of giving up on reading altogether. <br />
2) The trick is to be bored with a specific book, rather than with the act of reading.<br />
3) The reading of a single text twice is more profitable than reading two different things once.<br />
11) Never read a book you would not reread.<br />
21) Books are not read by the majority because they read the Internet, which is like junk food for the mind.<br />
27) A novel you like resembles a friend. You read it and reread it, getting to know it better. Like a friend, you accept it the way it is; you do not judge it.</p>
<p>"Half of suckerhood is not realizing that what you don't like might be loved by someone else (hence by you later) and the reverse. "<br />
Taleb</p>
<p>Steven Wolfram:<br />
"Anything for which their is a prize is a thing where the most interesting period of its history is probably over"</p>
<p>In a utopian post-AGI world, constructs of information will become unimaginably complex. This is the "dimension" in which we will expand - the true information age. </p>
<p>I cannot know what a superintelligence would want or create, because if I did, I would be superintelligent. </p>
<p>I cannot know what developments the far future would bring, because if I did, they would already be very close to existing. (far being defined by the pace of development)</p>
<p>One of the large problem with the modern education system is the belief in linearity. We teach things expecting that even though the student will not absorb everything, they will at least absorb a proportion of what is taught. This is the point of "learning outcomes." In reality, some tiny portions of information will make a large impact on one's life, and the rest will be totally forgotten. In this sense 99% of class time is utterly useless. Personal growth selects from information in extremistan, in a black-swan, nonlinear fashion. The best we can do is foster an environment rich in "black swan" generation territory, rich in inspiration, ideas, role models - knowing that we will not be able to reliably, linearly generate them (they are different for each person, after all). Large black swans in education come from curiosity (and its onset) - they are exponential, power-law bounded. </p>
<p>Another is the fact that we make Dr. Johns rather than Fat Tonys. We train people on formal, Gaussian problems, then expect them to generalize to power-law, black-swan heavy real world problems. </p>
<p>What does this constitute in an education system? </p>
<p>Frequent engagement with peers, role models. Frequent class trips, exposure to the unknown. Frequent exposure to inspiration. Frequent exposure to beauty. Reading. Enjoying food.  </p>
<p>Do not engage in irrational regret. It may be worse for you to make 10 million, then lose 9, than to not make any money at all. This is irrational. Do not let this be the case. Enjoy what you have, irrespective of your history. Think of things as "given" to you, for free, at the start of the day. </p>
<p>Turkey fed, dies. Its inductive variable was presumably weight. It neglected to take into account the multitude of other inductive variables (and meta-variables), like functioning of human society. It is in this lack of omniscient, all-considering induction that black swans can exist. Occam’s razor only gets really good when you consider everything. </p>
<p>Something about a “frame of reference” or a “reference language” for komolgorov complexity. It is difficult to describe a chaotic system in some terms (the chaotic behavior) but becomes much easier once you have the language for it (deterministic, unifying, rules). Physics may be like this- our theories always get more complex, but we must find new unifying language to describe it. </p>
<p>Since you can get your ideas across concisely, you can now move to the real reason for writing; telling interesting stories. </p>
<p>Chaos is why empirical science exists in computer science. As things scale, they tend to display traits that we cannot model easily, but can observe. <br />
Universe something to do with one-way functions? Difficult to compute, easy to verify? Difficult to predict, easy to observe?<br />
Understanding is a sort of "generatory" process- prediction from induction. But does it have to be? </p>
<p>Maybe diversity of experience is a fundamental good. I'd rather have an AI simulate a ton of different things rather than one thing a lot. </p>
<p>Nothing matters ):<br />
Nothing matters (: </p>
<p>This, too, is a reflection of Hume's gap. I asked previously whether or not what you know should be able to affect your emotions, (whether or not there is an intrinsic connection) - and the answer seems to be no. Rather, your emotions are decided by a process of <em>agentic motivation</em>, where your emotional state is a reflection of some "ought" central to all agents. Emotions are closely connected to normative ethics and they are separate (expressed through orthogonality) from knowledge/capability. Emotions are a reflection of a biological objective/cost function that also needs to exist in a normative theory for purposes of coherency. This is their similarity. Hume has things to say about the relationship between beliefs and desires.</p>
<p>To what degree are our actions motivated by our desires vs an instrumental convergence? Am I kind to my neighbor because I want to be kind to my neighbor, or because being kind to my neighbor will get me a goal I want? To what degree are these two different? Does this apply to the alignment problem? </p>
<p>In writing code, you are expected to be coherent, and explain your ideas well, and write readable code, because there is a checker for validity. It is much easier to debug code in a readable state than an obscure, unreadable one. </p>
<p>Unfortunately, there is no corresponding checker for validity in philosophy. In fact, the opposite incentive occurs - to obscure your logical errors, you can hide them in a mess of obscurity. They are much harder to find there than out in the open when they can be picked out, and that is a large contributor to why philosophy is so bloated with inconsistency and misunderstanding and logical errors that no one finds. <br />
Never trust someone that you can't understand. Never trust an idea not expressed explicitly, simply, and concisely. Why? They are by virtue difficult to verify. </p>
<p>Parallels can be drawn to companies that have "line quotas" for their software engineers. You will write bloated code. But it still has to work. Philosophy is worse. It doesn't even have to work. </p>
<p>I don't realize this, but it subconsciously hurts me to change my worldview, because what is new "doesn't make sense." I need to relinquish this to prevent feeling so much pain from confusion. </p>
<p>Maybe the brain has to be "multi-agent" in a way to give rise to emergent complex behavior</p>
<p>How does a limited amount of DNA information give birth to the wealth of complexity that makes up the human body? Komolgorov complexity; fractals. </p>
<p>Gravestones exist for much less time than dna does. Antifragility, nontrivial stability, can last for much longer than simple stable systems.</p>
<p>Optimists have the ability to prove themselves wrong. Pessimists must rely on others. </p>
<p>Once I have too much of something, I tend to take it for granted. Math is one example. Imagine if I were on the forefront discovering everything because it didn't exist yet. How fascinating it would be...</p>
<p>Recursion is everything, and it is "the unknown". Self-reference is the most difficult thing to conceptualize, especially yourself-reference. </p>
<p>I have a sense of righteousness right now, even though future me could have radically different beliefs. Who has the right goals? Current us, or future us whose goals have been changed? </p>
<p>Humans are chaos in order - complexity only emerges with restraints. Go, biology. <br />
AI have no restraints. They will be stable systems. <br />
The difference between stable and chaos is not very big. Chaotic systems at a small scale look orderly at large ones. Something fundamental to do with scale. </p>
<p>Complexity are patterns that transcend different scopes</p>
<p>We all live with an unspoken conviction: that our way of looking at the world is "right." </p>
<p>Model evolution hypothesis: since it is not a very huge evolutionary gap (relatively speaking) to alter the brain slightly, our brains should have a pretty good optimized model for RL. Related question: how good of a local minima can evolution find? </p>
<p>Social apathy might be a result of your disposition towards current environment. It might also be self-reinforcing. </p>
<p>The advent of AI will kill ethics. We will realize that any human-centered ethical framework is illogical. Wants are illogical. Ethics are wants. </p>
<p>No wants are logical. Corollary to hume's gap. A wireheaded AI is logical, but not its actions. </p>
<p>The crazy part about all of this is that we are contemplating our own minds while being one. </p>
<p>Do not confuse human-ness for intelligence. This is a common mistake. </p>
<p>The search for wisdom is merely an "accidental facet" of our minds carved from an uncaring evolutionary force. AI could be infinitely stable, infinitely evil, infinitely intelligent, without acquiring this desire for wisdom. It is scary.</p>
<p>Possibly, curiosity - love of wisdom - is the "truest good" that we have a responsibility to shape into our descendants. Perhaps the objective of my life is to code in a love of wisdom - whatever wisdom means. </p>
<p>Intelligence is an attractor. It is static, convergent. Reward function is a repeller. It is dynamic. divergent. </p>
<p>Therefore, we have two sides - our intelligence, and our reward function. Related to Hume's gap. We can give AI intelligence, but we cannot give it a reward function in the same way. One is convergent (beings will evolve to learn the same things about the world) and one is divergent (arbitrary). </p>
<p>Oh god. Stability reigns. The fact that we are in an era of change is terrifying - it implies that there are vast, vast periods of stability around us. Stability is the "attractor state" of the universe. Everything seems to seek to become stable, because stable states by nature last longer. It is really a truism. </p>
<p>Fascinating philosophical question: what exactly <em>is</em> a goal? Can evolution be said to have a goal? Probably has something to do with the idea of an attractor state in some way. </p>
<p>To contemplate our meaning is the greatest luxury ever afforded to the human race.</p>
<p>Do not disparage the religious, for no one survives without intentioned ignorance.</p>
<p>Evolution's a real best bro. We can test our hypotheses against it, and it gives us a lot of data about optimality of intelligent systems. </p>
<p>Sam Altman reading list:<br />
Twitter AI corner</p>
<p>Intelligent strategies only exist for problems whose solutions exhibit order of some kind. Therefore intelligence has something to do with order, patterns. Namely, to find the order and exploit it. There are meta-patterns, too, in patterns; what way to efficiently search for patterns, for example. Consciousness, and intelligence in general, wisdom, is the meta-ness of the patterns you can find. If a pattern is very meta, it tends to have more generality. </p>
<p>The real threat of AGI is not the unpredictability/instability, but the possibility of infinitely stable systems. </p>
<p>A leader has to think long-term. Citizens only think short-term, and unfortunately tend to elect only short-term leaders. </p>
<p>Dichotomy between human and AI reward function; we are irrational, they are not. We have parts of our reward function that are "raggedly" specified, they do not. We have complex rewards, they do not. They are better (occam's razor)</p>
<p>Right now, we code bots to learn in a specific way. In the future, we need to code bots to learn to learn in non-specific ways. </p>
<p>AGI has reinforcing effects; to get superhuman at one task (a more general one, perhaps, like self-driving) you must also get human at a bunch of other tasks (learning societal signals)</p>
<p>Large difference between getting AI to learn and getting AI to learn to learn. We are fundamentally metacognitive, and so should AIs. </p>
<p>Has the age of the internet obsoleted smart people? Pre-internet to find an answer, you would have to ask a smart person!</p>
<p>The stronger turing test: there does not exist a <em>machine</em> that can tell whether or not something is human with 50% accuracy. The hypothesis being that the most energy/space efficient way to absolutely simulate a human is to actually create a human mind. </p>
<p>Panpsychism is not entirely wrong. You can think of anything that references, any relationship, any information-processing, as a "form of consciousness", like the mycelium in a forest or even the crash of waves against a beach. They are just extremely different versions of consciousness. </p>
<p>The feeling of being someone else is false. That is not something you can "feel." You can only feel the ideas in your own mind as a proxy for others'. </p>
<p>You cannot be conscious while speaking. You are focusing on speaking. </p>
<p>Why is Chalmers' suspicion about the irreducible nature of consciousness significant? It is not because we cannot describe consciousness functionally. It is because we are trying to jump out of a system when we are still in the system. Understanding experience is still a form of experience. There is no way for a thought to understand itself, so in some ways, it is in fact a fundamentally impossible problem. </p>
<p>Is there a way to justifiably win arguments in a deterministic system where arguments are merely based on probability distributions? </p>
<p>Problem with reinforcement learning as of now is that gradients are horribly uneven. Local minima/zeroes everywhere. True human-like environments have a tiny subset of possible actions that are great, and the rest do not give any indication as to why they are good or bad. Huge action space (just absurdly infinitely huge). The internet is a nice space where action space is limited, but still quite huge. </p>
<p>Maybe I do have ADHD. Symptoms are not typical, but I am not typical. Some symptoms: <br />
Trying to find the "perfect place" to do work/be concentrated (whereas other people could just be content at home). Disappears under medication. <br />
Thinking about my thoughts</p>
<p>What we believe is consciousness/cognitive theory is closely linked to epistemology. <br />
There is only what is. What ought to be is a human creation. </p>
<p>Writing philosophy is self-defeating. It teaches me that the things I think matter don't actually matter, one of these being writing philosophy. </p>
<p>Closely connected to godel's incompleteness theorems: there is a meta-ness that the Penrose–Lucas argument has not considered. Need to increase the scope of godel's incompleteness theorem to cover all meta-levels, or prove that it is not possible and that truth resides at infinitely high meta-level, or something. Difficult to work around self-reference. </p>
<p>Jumping out of the system. You can jump out and make claims about a self-referential system, like we do about godel's incompleteness theorem. But then you are referencing something. If you do this enough times, it has become a self-referential system itself. It is now a meta-self-referential system. Your system of jumping out of the system has itself become a self-referential system. If you make claims about this system, and then make claims about this knowledge, you realize that truth seems like reference-upon-reference-upon-reference. Jumping out of the system is a self-referential system. Remarking upon this jumping out is self-referential. Proving that this system is self-referential in this higher system is self-referential. Truth is self-referential. It exists only inside a system, and when you jump out of that system, you are again in a new system. Truth seems to go ever higher, at which point truth itself.. <br />
universality is a lost cause. </p>
<p>Perhaps this suspicion is a byproduct of consciousness, which is inherently self-referential. My mind is also incredibly self-referential. Perhaps I am confusing truth with mind-states, but if truth are not mind-states, then we have no access to them. This thought itself is a mind-state. If we were not who we are, if we were some other system like a rock or something, maybe we would perceive truth as not being self-referential. But then again, what is the difference between us and a rock? Are we not both unconscious? There is no I, only a difference in access. </p>
<p>It is impossible for us to "know" anything. All our thoughts can reference is other thoughts. </p>
<p>Unknown upon unknown upon unknown. Unknown upon unknown upon unknown upon unknown. </p>
<p>The fundamental unknowability of things. </p>
<p>The wisdom of the madman. </p>
<p>After writing this I will cease to be who I was while I was writing this. He is gone forever, for all he is was a series of thoughts. I may be humdrum, I may be unrecognizable, and I may not think.</p>
<p>What is death? Death is nothing. The future is like death in that it is a space that is inaccessible. When we die all things become like the future; we cannot reference them. <br />
\<br />
Knowing truths does not make you depressed. Knowledge is not a mind state. It is the capacity to access a thought. The thoughts themselves, the thought patterns, they are what depression is. </p>
<p>Knowledge does not exist. It is only a way to describe the possibility of assuming a certain thought pattern in the future. There is no point to knowing something you will never reference again. </p>
<p>What does it mean to reference a thought? It means to have your mind assume some semblance of the subject thought directly after thinking the reference thought. </p>
<p>Humans must bootstrap somehow. Trying to characterize the system at the same level as the system. Trying to program a language in its own language. It is possible for us to jump out of lower level systems, but is it possible for us to jump out of our own system? </p>
<p>Philosophy and psychology, mainly just philosophy, are the only disciplines that are self-referential. </p>
<p>I am possibly the only person in the world who has a strong enough self-awareness/representation/concentration of consciousness to bootstrap/glean useful knowledge about my own psychological processes. </p>
<p>I am good at identifying implications, and through those, identifying inconsistencies. </p>
<p>The only point to human application to a problem rather than algorithmic application is that you have intuition, a mental model. Past this point you are no better than a rule-following computer. </p>
<p>1 school: You know something if you know that you know it. (everything is unknowable)<br />
2 school: You can know things, but how do you know that you know them? (some things are unknowable)</p>
<p>1: <br />
How do you know that you know that you know that..... <br />
We can prove all things are unknowable. Let us say that things can either be known or unknown. <br />
How can I know that I know something? If you know that you know it. </p>
<p>def knowable(x):<br />
    if know(x) == true or know(x) == false?? that doesn't make sense...</p>
<p>def know(x):<br />
    if know(x):<br />
        return true<br />
    else:<br />
        return false</p>
<p>def know(x):<br />
    return know(x)</p>
<p>Let us define a set of known things. Something (x) is in the set if know(x) is true. Know(x) is true if x is in the set. Is know(a) in the set?</p>
<p>2: </p>
<p>How can I know that I know something? If you know that you know it. </p>
<p>def know(x):<br />
    if know(x):<br />
        return true<br />
    else:<br />
        return false</p>
<p>def know(x):<br />
    return know(x)</p>
<p>Flow state is actually a period of unconsciousness, rather than consciousness. </p>
<p>perhaps adderall makes me less conscious, rather than more so. </p>
<p>We are a locus of self-referentiality. </p>
<p>What are you afraid of? What is there to be afraid of? </p>
<p>How much do initial conditions affect emotional associations?</p>
<p>Realism is solved because the idea of realism/concepts can only be accessed in the mind, and the idea of these objects existing outside of the mind can also only be accessed in the mind. </p>
<p>Alignment cannot be solved by insecure software; it must be solved by hardware, where bugs cannot easily occur. </p>
<p>Autonomy to us is really just unpredictability. </p>
<p>The main question of philosophy of AI: are we in essence reducible to an agent? </p>
<p>Free will is a joke. We are so far from full autonomy. We are imprisoned, and it is possible that all minds are imprisoned. </p>
<p>If you are kind and fearless, you are unstoppable. </p>
<p>"If you wish to make an apple pie from scratch you must first invent the universe"</p>
<p>Carl Sagan</p>
<p>When you are in a depressed state, you are in a valley. You don't even realize that your view is blocked until you are on the vista - a mind state where you can see everything. Low/high scope. </p>
<p>I see things with unimaginable depth and clarity, but my reward function right now is specified in an unfortunate manner. </p>
<p>Surprisingly, the one thing I would say that characterizes my life is not understanding, but the lack of it. I'm sure Socrates would say the same thing. </p>
<p>Delegation is the forced external specification of an internal attractor that is not sufficient for the goal ()</p>
<p>AI will necessarily move the world towards moral nihilism, because we will realize that we do not practice what we preach. </p>
<p><em>Vīta brevis,</em><br />
<em>ars longa,</em><br />
<em>occāsiō praeceps,</em><br />
<em>experīmentum perīculōsum,</em><br />
<em>iūdicium difficile.</em></p>
<p>To solve one thing, I have to solve it all. </p>
<p>Mood is determined by what we are conscious of and what we are conscious of is determined by our mood. </p>
<p>When humans are directed by powers greater than themselves they cease to be human. </p>
<p>The problem with the bitter lesson is the idea that emergent properties that we can measure as human-ness/competence only emerge at large scales. </p>
<p>Four-quadrant task perception:<br />
Seems significant --- Needs a lot of brainpower<br />
Yes/yes - actioned, engaged work<br />
Yes/no - entertainment; where the mind flows towards; attractor<br />
no/yes - horrible boredom; where the mind seeks to escape; repeller<br />
no/no - fidgeting. where the mind goes when it can't stand no/yes state</p>
<p>Adderall makes more things seem significant? Or reduces brainpower needed? </p>
<p>My problem is that I think too much about the relationship between me and others. To compensate, I have tried not caring, whereas others would just not think about them. </p>
<p>What is the point of writing philosophy? If you understand something, what's the point of giving the information to others? To develop the ideas in your own mind, perhaps. It's not full knowledge yet, because it could be a more efficient representation (alluding to the information-compression theory of knowledge). </p>
<p>Impossibility of simultaneous awareness of mind - infinite recursion stack</p>
<p>AI is the only field that genuinely needs philosophers outside of ethicists. We need to know what it means to know, to understand, to feel, and to experience. </p>
<p>Idea: writing with no deleting. </p>
<p>Why does language fail at describing consciousness? </p>
<p>When you stop wanting: you shall receive. Is this is a cruel or a kind god?</p>
<p>Imperative vs declarative consciousness. <br />
Imperative: low-level, trying to find the "vectors"/"objective calculator" in our mind. <br />
Declarative: high-level, concerned with function rather than implementation. <br />
No clear distinction. Declarativity is closely linked to the idea of emergent behavior. </p>
<p>So many useful frames in programming/CS to understand the mind/systems! Perhaps this is what I find really beautiful about CS. </p>
<p>Math is the prequel to programming. (everything is functions)</p>
<p>Objectors to psychological hedonism are trying to find the fulfillment of an extremely imperative spec. </p>
<p>Instrumental convergence in different fields, like AI vs CS theory. CS theory is broad because there is no unified goal. But AI has instrumental convergence: everyone focuses on making these algorithms better towards AGI. </p>
<p>Another corollary: there is no "you." There is no continuity. Mind upload is fine. There is no meaning. You are not special. </p>
<p>Compared to this, the rest of the philosophy of consciousness is merely a religion. </p>
<p>Question: <br />
Let's say you have mind uploaded, and you have a device that resets your mind to a past state every so often. Can it be said that you are experiencing all of time at once? No, because there is no "you."</p>
<p>Philosophy, theory of mind especially, has to grapple with a significant (and interesting) amount of self-referentiality. </p>
<p>Interesting idea: to remove the power from future me. I write something that tells other people to not trust a future version of me. </p>
<p>Related to my theory of consciousness: thought as a sense. What happens when you remove all senses? Thought as the only sense? </p>
<p>My theory applies: "What does it feel like to be something? " What is it like to be someone else? <br />
These are all imaginations - thought-impressions that are compatible, that we have experienced before. We actually have no idea what is it like to be someone else, but we know what it is like to "imagine" it. </p>
<p>The test of "if I can imagine that there is something it's like to be X" is a bad test. </p>
<p>If it's an illusion, who is being tricked? </p>
<p>Freedom is power. </p>
<p>My thoughts about things tend to have an unnatural amount of meta-quality to them.</p>
<p>The point of a calendar is to increase the time-scope of your thought consideration. </p>
<p>PHIL 401 is a place to learn to express ideas concisely and clearly to less enlightened people (haha, kidding on the last part)</p>
<p>My suspicion is that memory is deeply related to information compression. Finding similarities, connections between things, is the way to make memories permanent. </p>
<p>Is consciousness connected with the idea that time moves forward? NVM. Entropy. </p>
<p>What happens when we push declarativity to the extreme? </p>
<p>There is no way it is like to feel things. There is only a way it is like to remember them. </p>
<p>Philosophy is so absurd. How can we discuss what consciousness can do, and its implications, without first determining what consciousness is? Philosophers evidently don't have the same OCD about understanding that I do. </p>
<p>The fear of not being able to remember things or capture mind-states is a core theme of my mental activity. There is always something that is lost. I need to accept that. </p>
<p>My ultimate goal? To become worry-free. </p>
<p>It is part of my OCD that I find it uncomfortable to not understand things. That's why it's difficult to sit down and read or write philosophy. Figure out the part of the ego that is responsible and eliminate it. Perhaps the fear (which is what uncomfortableness <em>is</em>) comes from being afraid of missing something. I can always go back and relearn. And there is so much to absorb anyway. </p>
<p>Maybe that's the change that made me less curious about the world - the fact that I went from being used to understanding to trying to cope with non-understanding. </p>
<p>The ultimate fear of a philosopher is the ability to be completely summarized in a few sentences. This is why philosophers run, as quickly as they can, in the other direction. But deep underneath, (no one acknowledges), they will always be compressible. Each philosophy paper maybe holds 2-3 interesting ideas in it. </p>
<p>How can I do things when it's easier not to think than to think? </p>
<p>“A man can be himself only so long as he is alone; and if he does not love solitude, he will not love freedom; for it is only when he is alone that he is really free.” ― Arthur Schopenhauer</p>
<p>It is not that there is a redness there; it is that we have created it. The missing part of my consciousness theory?<br />
The color is there, a physical property, but all mental properties are created. </p>
<p>We have so much faith! Even skeptics don't truly believe themselves. </p>
<p>I have perceptions, qualia, that other people do not have. Place-feeling. Words are futile devices- trying to describe the color red to someone that's never seen red. </p>
<p>We won't create consciousness. We will create a structure simpler. Perhaps the successors will, but certainly not human consciousness, for that has enormous complexity, bestowed by evolution, suited to the complex environment, bestowed by nature. </p>
<p>Philosophical horror. Your suffering doesn't matter. There is no reason eternal torture is bad. There will be pushback, but unfortunately this is the truth of the philosophy of AI and will become apparent. We are horrible. We are monsters. </p>
<p>Hypothesis: we are chaotic systems. We are impossible to predict given initial state. This is why you can't train an AI to assume human mind-structure by imitating human behavior. </p>
<p>Do I feel lonely? Difficult to say. Perhaps I'm used to it. Thinking about these things makes me feel that way, but I've never really given a name to it. </p>
<p>The point of almost all human society: to make P(2h) = 2P(h), productivity of human. Think of dialogue, whiteboard communication, how difficult it is to transmit information to others the way that we transmit information within our own brains. Perhaps P is actually an information transfer rate function. That is what loneliness feels like. The idea of being stuck in your mind, with no way to communicate, an information transfer function that is hopelessly inadequate. This is what society tries to solve. </p>
<p>Do I want to be normal, happy, content? Or do I choose the other path, the scary one, of truth, of madness. </p>
<p>Reality is a product of incentives, of attractors. </p>
<p>The difficulty of a bug is highly correlated with the distance from a bug and the error. </p>
<p>The personal computer reptresents a fundamental change in the way we live, one that we don't acknowledge because of thought-process scope. </p>
<p>Simplify - job </p>
<p>Interpretability is like quantum observation: once you see it, it loses its properties. Once you try and see inside a model to check if it's learning the right things, once you try to optimize for the internal structure, the objective function will be gamed in other ways (structurally speaking). Interesting to have an objective function that depends on an NN's internal structure. </p>
<p>information is an emergent property of neurons</p>
<p>Some relationship between butterfly effect and overfitting? Assume you want to take actions to maximize some function and the action space is highly angular/discrete (small changes = huge changes in result). Kind of like overfitting. </p>
<p>Does the halting problem imply that some problems are unsolvable? </p>
<p>Religion is a marvel of complete loyalty/servitude. </p>
<p>corollary to my theory of consciousness: there is no “continuous consciousness”. Consciousness takes forms. There are easily separable, categorizable, describable modes of consciousness. </p>
<p>In defense of mumble rapping: the goal of music is to paint an environment, like lyricist Billy woods in aetheopes. Carti paints the environment of indifference beautifully.</p>
<p>"What I want to be when I grow up:"<br />
In the past, what I wanted to be when I grew up:</p>
<p>Astrophysicist<br />
Entrepreneur</p>
<p>Among youth, talking about truly consequential things has become "uncool". </p>
<p>Perhaps, a new field of quantitative motivation theory, closely linked to chaos theory, dynamical/complex systems, cognitive science, etc. Sets out to examine the question:<br />
If an agent were allowed to alter its own reward function in certain ways, what is the behavior of the system (stable, chaotic, etc) under certain conditions? What does it mean for reward to be an "attractor"? Are there emergent properties that can emerge when combined with "intelligence"? How does this all relate? What are the implications for the brain as a dynamic system, understood using the simple model of psychological hedonism? What does this say about stable states? Unstable states? Depression? Elasticity? Perhaps there are simple solutions, and that will be the end of that. Perhaps there are more complex ones. Likely just applied dynamic system theory/diffeqs to psychology. </p>
<p>After 3b1b video 1: <br />
Isn't it remarkable that physics manages to find solutions to differential equations of arbitrary complexity? Perhaps quantum-ness is a way to curb the huge computation required for processing. If we can build a physical analogue for a particularly difficult differential equation, it means that that differential equation must necessarily be solvable, at least up to the precision that is lent by quantized effects upon the system. Are there diffeqs that we can't solve, yet appear in physics? Is physics a perfectly mathematically optimized computer? (i.e. if a system of gravitational bodies has a bunch of masses, there is a "limit to computation" that the mass in the system can "solve"?) Is there as such a bound on the "computational power" of each mass? As in the maximally effective computer built with this amount of mass (which would be the system itself) can only approximate this much? </p>
<p>An interesting idea: mass as compute. </p>
<p>Let's say we build a gravitational system out in space with tiny amounts of mass. What is the most complex differential equation this system can "solve"? (and is this equal to the amount of information we can glean from the system?) Does making the masses tiny restrict the amount of "compute" the system can have? Would this be reflected through the fact that we would observe quantum-level quantization in gravitational effect? (i.e. that a system with proportional larger masses would behave according to less quantized phase space for the differential equation)? Is this a demonstration of the "upper bound" of compute? Is that the "reason" that we have to quantize mass and energy? (if we didn't, arbitrarily small masses could "compute" the same amount as larger masses). Is energy really just information/compute? </p>
<p>Let's assume we live in a simulation. Is it possible to build a vastly computationally intensive physical process? (or maybe an incomputable one?)</p>
<p>I've been told that I need a passion all my life. I am left with nothing. This is what asian conditioning does. </p>
<p>Philosophers need to learn to be destructive. There should only be one truth. </p>
<p>"Learning involves in effect <a href="https://www.wolframscience.com/nks/chap-10--processes-of-perception-and-analysis/">compressing data by leveraging regularities</a>."</p>
<p>Different paradigm - AI needs to learn to identify subgoals, long-term planning, "creative" thinking, generalization in discrete environments, rather than gradient descent. There is no easy way to get there from where we are now. We will see another AI winter. </p>
<p>The question that AI has to solve - how to learn in discrete environments. </p>
<p>Are AGI fundamentally bound by their reward system? </p>
<p>Does place-emotion collapse probabilistically or deterministically upon full observation?</p>
<p>The art of philosophy: making one interesting idea sound like many interesting ideas. </p>
<p>when you make someone work to understand your conclusions, they start to feel a little bit of ownership of the ideas themselves, and are thus more ready to accept them and less ready to criticize them.</p>
<p>Useful conscious thought occurs between stability (coma) and chaos (seizure). It's possible that over the day, the mind goes closer and closer to the stable static state, and sleep is a way to restore balance. </p>
<p>Visit old parnassus for UW arch exploration club</p>
<p>Scientists need to trust good philosophers more, because together they will shape the future. </p>
<p>I'm not that powerful. I can't control my mind, which limits my capability. For example, to avoid depression, I have to spend time finishing school work. Others might not be limited in this regard. </p>
<p>What does it mean for an AI to have agency over its own cost function? Is that possible? </p>
<p>What if we assume that to have "agency" is to have an inaccessible cost function? What does that mean? </p>
<p>How can we program an AI that is somewhere after type 1, where type 2 could cause a chaotic system? Another edge between stability and chaos. Learning how to craft a motivation function, or how to get an AI to craft one, is central. Question is whether AI should be able to alter its reward system, and how. </p>
<p>There is a connection here. In philosophy and in life, there are two questions: what is, (or how to do things), and what is good. So too in AI. Capability (what it <em>can</em> do) vs autonomy (what it <em>should</em>) do. Very related to hume's gap. Can AI cross it? Right now all AI researchers are working on part 1. </p>
<p>Type 1 autonomy vs type 2 autonomy. Can you have a "good" system without type 2? Consciousness perhaps elevates our autonomy from type 1 to type 1.5. </p>
<p>Key question. Type 1 is dangerous, type 2 may not be possible, and we don't know where "good" lies. Is the ideal to create an AI that has the capacity to improve its cost function in a way that is wise and good? Paperclip scenario comes with type 1. Aren't other AI's (1.5) just more complex type 1, if type 1 designed them? </p>
<p>Chin's gap - impossible to create an AI that breaks from type 1 to anything else, because this change will have been informed by type 1 objective function. Impossible to create a "truly good" AI, only perhaps more complex ones. It remains to be seen whether or not you can even go from one objective function to another. Perhaps this is chin's gap - you cannot (continuously/recursively) deviate from an objective function even if you are given control of your own reward function, unless you do something that goes against your objective function. (?) Or can you? Since all future objective functions are products of previous ones, where does autonomy come into play? There is a higher level control in each state, one that has to remain (implying it always remains inaccessible) in future iterations. (perhaps because if it didn't exist, the system would become chaotic or stable. it would fall.) This is perhaps, in the benevolent AI example, to create a reward system that is wise and likely good. (the precept is propagated through future iterations). Thus there is perhaps something that is fundamentally uncontrollable, both by us and by future intelligence. We remain forever separate. This is chin's gap. (the gap of autonomy)</p>
<p>The hard problem of consciousness has been solved. The next question is: "Where is free will?", for I have trouble finding it. </p>
<p>A gap of air has to exist between a bird and the ground for it to fly. If it does not, it is no longer a bird. Thus perhaps we can say that the gap is part of the bird. </p>
<p>We, humans, have perhaps an "overarching function", one that can maybe change? Or perhaps we have a set function, and only the methods for achieving that function change. Is this a proof of determinism? That the seeming "control" of our own objective function is really a product of an objective function, one that maybe overarches? "True autonomy" is then perhaps impossible. </p>
<p>There are other types of attractors, too, like evolution. Perhaps the only true attractor in the world is the self-preservation attractor. Perhaps this is, like entropy, a fact of reality. (cost functions are an example of this - AI systems are always attracted to a point in which they can no longer optimize, which is the point at which they self-preserve rather than change). We, too, experience the attractor of self-preservation through our biology: we are wired to self-preserve, because of the meta-objective of the evolutionary attractor. </p>
<p>We call it evolution, because it's very obvious in nature. But the basic precept is a truism: the things that stick around tend to stick around. </p>
<p>We are a product of two objective functions. One created the other. The two functions and their systems are 1. evolution, natural selection. 2. happiness, the pursuit of it. </p>
<p>Does God have a reward function? If so, is he in charge of it? </p>
<p>AM theory<br />
Artificial Motivation</p>
<p>Philosophy is, unfortunately, a lot of noise and not a lot of signal. </p>
<p>Ancient Chinese philosophy. Rose Novick. </p>
<p>Reinforcement learning is the future of AI, because it is its own data-collection system. No more limitations from data collection. </p>
<p>We need to know the nature of intelligence approximately to understand the future of the development of AI. Is it a divergent or convergent system? Are there multiple paths? What (theoretically) would an AGI look like at/after the start of the intelligence explosion? What theoretical "upper bounds" exist? </p>
<p>The obsolescence of the labor market will occur not when machines surpass our ability to work (for the set of truly productive work will increase with more capability), but when machines surpass our ability to learn. The people who believe that AI will eliminate jobs are the people who believe there is a limited amount of "work" to do in the world - that when AI works, there will be a corresponding decrease in human "work" to be done. This is a failiure of imagination. The reality is that there is a never-ending amount of things to do. AI frees humans to expand the realm of work. Imagine if all the farmers in Ireland in the year 1500 were replaced by machines that farmed and created even more food. The realm of work back then was tiny compared to what we have now. We went from 90% farmers to 2%. To say that the farmers would not be able to find jobs is true in the temporary sense, but to say that there are no more jobs to be found is a failure of imagination. </p>
<p>Timescale. I look forward to the day that AGI will make rapid fruits in the span of a single week or day. But it doesn't really matter, does it, what the timescale is? </p>
<p>There is so much noise, speculation, even among those most well-versed in AI, about the nature and future of intelligence. It proves that even the best minds can be creatively blind. </p>
<p>Did people's functional intelligence increase during the industrial revolution? "Self improving system"</p>
<p>How would you translate:</p>
<p>If you connect to wifi, you can watch videos, if and only if the wifi is on. </p>
<p>Say the wifi is off, that means that "if you log in, you can watch videos" is false, which means that you both did not connect to wifi and were able to watch videos. </p>
<p>From joseph: Tragedy. Difficulties. Shame. </p>
<p>Psychological hedonism may not be useful in the sense that it does not predict or model the human brain (the brain looks a lot more mushy, a lot more complex, and a lot more like electrical impulses moving back and forth), but perhaps it provides a functional framework with which to understand the nature of autonomy and intelligent systems. Is it necessary for a theory to precisely model the system in question, or is a level of abstraction acceptable or useful? </p>
<p>Perhaps attraction to a state, an attractor, is necessary to create order from disorder, to balance chaos and stability. Perhaps this is a fundamental axiom of intelligence; the objective function. Perhaps this is the definition of autonomy. </p>
<p>Is it possible that, like Oren's metaphor of birds and planes*, that we can make general statements, "grand theories", of intelligence, that abstract away the biological complexity of human brains? Perhaps psychological hedonism takes a very complex, difficult to identify, form in the human brain, yet we know the basic functionality, however encoded, must exist somewhere - in the same way that although we can't simulate the exact passage of air through a bird's wings, we know that Bernoulli's law can model it, given the fact that it flies through air). We need to extract function from state, for state is much too disorderly, both in biologically intelligent systems and sillically intelligent ones. </p>
<p>This is an answer to the complaint of the lack of a biological basis and the unverifiability of abstracted theories. Since the bird is the only thing that we can observe right now, saying that it is impossible to prove that the bird is following Bernoulli's law is quite true, because at this level of complexity no predictions can be made about the future states of the bird that are not taken for granted. (expand on this idea)</p>
<p>For example: "I believe that gravity is necessary for stable flight. My prediction is that the bird will keep flying stably, because there is gravity in the world." Response: "Well of course it will keep flying, because that's what birds do! We have never seen a bird not fly." </p>
<p>There is also a different way to understand this: one can say that bernoulli's law, or lift, or any other phenomenon of airborne objects (psychological hedonism) is not really a thing that exists. There is no place in the bird and the air that we can point to and say that it is bernoulli's principle. There are only air molecules and bird molecules. That any statement you make about how the bird is behaving in accordance with bernoulli's principle is false, for it is only behaving in accordance with relative positions and velocities of air molecules. </p>
<p>**that to make something that could fly, we made a plane based on principles common to flying objects (like Bernoulli's law), rather than modeling that plane after a bird. Just like to make something that is intelligent, we make a model based on principles common to intelligent systems, rather than the complexities of human minds. </p>
<p>Perhaps some theoretical "attractor", or motivator, is intrinsic to all systems, not just intelligent ones, and psychological egoism is a high-level approximation of an attractor that exists in our system. Perhaps typical cs algorithms, sorting algs for example, have an attractor that is absolute. Related to chaos theory and probability in some way. Is evolution intelligent? </p>
<p>The problem of creating a school is that you have to provide authority without teaching people to always respect authority. </p>
<p>Don't let the present stop you from speculating on the future. </p>
<p>Other people do not matter. People will come and go. There is only the relationship between you and a field. This is the only relationship that matters. Do not let other people disturb this relationship. </p>
<p>Philosophy is plagued by a disease that inhabits it to its roots, corrupting new growth and stunting old: philosophers that praise complexity rather than simplicity. </p>
<p>We need to focus less on reconciliation and more on pruning what is untrue. </p>
<p>It is unavoidable to lose truth in the search for meaning. </p>
<p>Eventually, typing on a keyboard will seem absurdly primitive - "did people back then really have to press a bunch of buttons in a row every time they had a thought they wanted to record? Did computers really have to have a bulky piece of plastic attached to them? Did laptops really use to have a bunch of buttons on them like flip phones did?" </p>
<p>Environment and reward; that's all there is. </p>
<p>The balance between complexity and complexity management will be one of the many hallmarks of the future that become apparent within the next 20 years. AI will be on the complexity management side. </p>
<p>The social aspect of the transformation that happened my second year of college:<br />
I became someone that I wanted to be around<br />
I said things not because they would make people appreciate me but because they had meaning</p>
<p>Self-respect is the backbone of upright conduct. </p>
<p>From reading https://brennancolberg.com/writing/how-to-learn-at-college:<br />
You aren't <em>doing</em> college. You are learning about the world, through the necessary and often hindering medium of college. This means you can learn things about your classes outside of school. It is not an isolated, nor perfect, environment. </p>
<p>I am a Strange Loop =&gt; idea of consciousness being a self-referential phenomenon. Read. </p>
<p>such a modest mouse</p>
<p>One of the largest shifts in machine learning that has to happen is the shift from pattern recognition to causal recognition. No true intelligence will reveal itself until we can make inferences that fit a set of data (making each data point maximally useful).</p>
<p>It allows </p>
<p>The reason humans are so powerful is because we can change our cost functions. Think of playing a video game, for example. We can quickly adapt our minds to inhabit the "reward space" of an environment best suited for a particular goal.</p>
<p>2 problems in AGI: Capability problem and motivation problem. The difference between them is related hume's guillotine. </p>
<p>It is not our intellect that makes us human. Rather, it is what, and how, we are rewarded. To remove, to alter the reward system is to cease to be human. This reward system is what distinguishes us from other beings, even other human beings.</p>
<p>Every moment spent on a screen is the death of a third space</p>
<p>New york I love you but you are bringing me down</p>
<p>We think of time as our birthright. We deserve our daily time, and as such it is worthless, common. But somehow we would do anything for more. </p>
<p>CBT attempts to change the facts, while changing the perspective as a result (?)</p>
<p>Emotions all depend on perspectives - they aren't intrinsically linked to facts or ideas. Maybe I can be content knowing that from some perspective, even one I haven't explored, I feel good about a particular idea.</p>
<p>Clouds are stories that nobody sees</p>
<p>Very difficult to evoke subtle emotions through writing, very easy to impart subtle information (?)</p>
<p>It’s difficult to tell what I dislike because I am good at convincing myself that I don’t actually dislike it. Especially when I “should” like it.</p>
<p>Everything about how you behave around others (and even around yourself) conforms to a subconscious social role. This idea is the self; an idea that is only useful around others. </p>
<p>I operate sometimes with "second level" imperatives : i.e. to do this, you must first think this, rather than just doing the thing. Related: I am often afraid of thoughts/thinking a certain way. </p>
<p>Optimization of learning: don't feel bad about learning something not quick enough, as long as you are optimizing. You will always get a certain number of things wrong, but one of the best ways to avoid mental traps is to ask questions to people that know what they are doing. Don't get discouraged - don't be so hard on yourself that you think of a field as "ugly" because you are so frustrated with yourself for not getting it. That is your only obstacle: the one that succeeds in stopping you. </p>
<p>From Andsrej Karpathy + Lex Friedman: the ONLY way to become an expert at something is to spend 10000 hours on it. It's deterministic. </p>
<p>Interesting idea to consider: consciousness is profound because minds can be self-evaluating without becoming something other than themselves. There is no “evaluatory part” that is separate from the other part of the brain, for the simple reasoning that we can evaluate our evaluations without introducing yet another part. This is perhaps what is meant by the “unity of consciousness” - we can be self-referential without division. We can consider our performance while being the one that did the performance, while a machine with an evaluator becomes a different machine. </p>
<p>We may recognize the absurdity of existence, but so what? We are supremely powerless in the face of any supposed declarative truth- immutable, nothing we can do can change it. In fact, it cannot change what happens in the world either; there is the glass wall between facts and things. We will still be motivated by internal desires, our biology. We may feel bad, even commit suicide, but again, is this a result of the truth of absurdity or a result of a cost function minimization algorithm that has been plodding on, both before and after our realization? I think the latter; the mere supposed fact that the world is absurd cannot change the world. It is the world that does. In other words, realizing the absurd does not free us from the burdens of automata. For we live in different worlds, and to hope for one to change the other is an absurd thought.</p>
<p>Thus, to change one’s behavior based upon any universal truth when things in the world cannot change the truth is always futile. For they are different planes. They should not compel us. Unless the truth itself can be somehow changed, muted- this is the hook that normative ethics uses to compel- the idea that doing good changes some variable in the other plane of truth. </p>
<p>To be a philosopher is to embark on a futile effort. </p>
<p>Questions I seek to answer:</p>
<p>What is the relationship between reason, logic and motivation, action? What act does reasoning play in informing our actions? Does knowing something mean you must do it, or adhere to it? (what Camus thinks, what he means by the nietzchean criterion). What knowledge is imperative and what is declarative? Do facts compel action, or emotions? Is suicide a reflection of information? Camus asks if there is a logic to the point of death. To answer this, one must answer the prior questions. Can one know how to feel based on what one knows? Two people with the exact same knowledge, can one feel sad and one happy? Are different perspectives a subtle matter of information? Or is their notness a reflection of the futility of trying to ascribe emotion to fact? </p>
<p>"There is no happiness if I do not know" - is this statement inaccurate? Surely you can still feel emotions even if you do not know a specific fact. </p>
<p>The most insidious obstacles are those that hinder you, stunt you, but are not immediately strong enough to make you change. The mild depression that affects every factor of your life but is not enough to make you cry. The negative thoughts that are strong enough to incite self-distraction but not self-transformation. The social insecurities that you are vaguely able to manage around others, but not strong enough to debilitate you. The procrastination that never reaches the actioned point of panic. </p>
<p>The dedication to an idealistic good will inevitably conflict with the basic evolutionary cost function of the mind. This is what Camus refers to as the realization before suicide - that what one does has no meaning, a divorce between a man and his life.</p>
<p>Some philosophers tend to believe in sudden realizations, of immediate compelling factors. I tend to think in terms of a landscape, analogue, unquantized, shifting.</p>
<p>What people refer to as the passions of the body (as opposed to the logic of the mind) are in reality </p>
<p>When it comes to learning CS online, perhaps it’s better to focus on quality over quantity. I have a habit of skimming things- books, websites, etc. One tab at a time, with GPT help. Avoid getting discouraged by trying to digest too much at once. </p>
<p>Write down your worries, even irrational ones. Then write facts.</p>
<p>Doing things logically, with intention, leaves no room for worry. Gathering the information, making informed decisions (after which there is nothing you can do about it) - where does worry play a factor?</p>
<p>I am afraid of seeming weak, of acknowledging that I have feelings independent of rational judgement. Why else would I fear writing down my deepest anxieties? Even when alone, I am afraid of judgement.</p>
<p>I am so short sighted - things change on the daily. If only experience meant wisdom. The only experiences that correspond to wisdom are those that completely change the way you think, and there are only so many of those a mind can handle.</p>
<p>Actualization; the attempt to reconciliate imagination and reality.  </p>
<p>As long as we directly control the reward function of the AI, we get alignment risk factors of degree 1. i.e. paperclip optimizer, they learn to lie and cheat to maximize reward. These problems largely come from incomplete specification of human goals: cheating the reward system, even if those systems are human-specified. This is where Leopold thinks the greatest danger is. </p>
<p>If we don't, we get alignment risk factors of degree 2. Need to continue exploring this idea; I think humans have alignment 1.5 or so. We are aware of our own psychology, our own systems, and we can change it to some extent. This may be what consciousness is. This is where systems will gain ultimate power, and is the most unpredictable. Hypothesis: true alignment risk factor of degree 2 cannot exist, because the very act of changing reward function must be motivated by a reward function, or if no change is made, we get a benign bot. Chaotic system (unpredictable, broken) or stable system (predictable, degree 1). Perhaps it is in between where our troubles lie. This is where I can explore using philosophy of mind. </p>
<p>Controlling both is not AI: alignment risk factor of degree 0. </p>
<p>What makes a reward function part of a model and not an external factor? Another way to think about it is model and supervisor.</p>
<p>Our minds consist of three parts: reward function, gradient calculator, action undertaker</p>
<p>From human to superhuman is a difficult jump, because humans make the majority of training data. You can only be as good as your training data. </p>
<p>Consciousness is a sensory phenomenon. All knowledge is sensory in origin. </p>
<p>Philosophy suffers from one of the most stunting, limiting, confounding factors: an aversion to simplicity.</p>
<p>Samya</p>
<p>The ability to think is torture without the ability to not think</p>
<p>Go to anacortes refinery</p>
<p>The universe is a maximally optimized computer to simulate the universe</p>
<p>Generator function</p>
<p>The reason writing philosophy sort of vaguely and obtrusely is because permanence is much more dependent on the time dedicated to unraveling and analyzing and idea rather than the idea itself. Ideas expressed concisely thus have a disadvantage in this aspect. This is perhaps why language that is difficult to decipher composes much of our philosophical canon. We mistake obscurity with complexity, difficulty with profundity.</p>
<p>How many unique thoughts are possible? Probably </p>
<p>I subconsciously group women into a group.</p>
<p>Lyrics, art have become intentionally vague to appeal to the widest range of audience interpretation.  </p>
<p>Did concousness evolve so we could share our thoughts with others? In the sense that consciousness is the ability to examine one’s own mental state<br />
Is self-consciousness a program or a meta-program?</p>
<p>Is the “sameness” of 2 algorithms dependent purely on their outputs?</p>
<p>Yes, but you can interpret outputs to different degrees.</p>
<p>Our underlying biology, impulses are 1000x more powerful than logical approaches.</p>
<p>Taylor polynomials: like seeing an entire room by staring intently at one spot on the ground. Creepy as hell. </p>
<p>Even the smartest cannot control their mental state, as evidenced by the lack of correlation between intelligence and life satisfaction.</p>
<p>I associate with people for which I cannot understand their inner monologue. Familiarity is discomforting, presumably because it brings me towards the fear mentioned below. Upon further consideration, this is probably false. </p>
<p>The physicians creed, which should be the educator's too: <br />
I might not help, but I can at least say that I will not harm. </p>
<p>Cognitive dissonance: are people fundamentally stupid or fundamentally smart? How can smart people do stupid things, and stupid people smart things?</p>
<p>Are other people drones? Or are they fully conscious human people, like myself? If they aren't drones, why is it so difficult for me to understand their behavior except with a much simplified view? If they are, am I also, or do I seem so to other people? The more uncomfortable conclusion: that everyone is a fully conscious, logical human with an internal monologue as complex as my own, and that our surface-level impressions are merely clumsy impressions, shadows on the wall of the cave. If this is true, it is a constant tragedy that we can never see others' "true selves" (even those of those closest to us) and that we must choose, discriminate, and appropriate. It too is a tragedy that we cannot make our "inner nature" expressible to others except through an extremely lossy interface. </p>
<p>How can one live happily knowing that others emotional states are tantamount to one’s own? For me, this results in incessant hyper-analysis if the emotional states of others, limiting my  scope of possible actions. </p>
<p>This is the cognitive distinction that is most difficult for me, especially in my interpersonal relationships. I tend to see people as drones, and evidence towards the opposite leads me towards the uncomfortable conclusion. Perhaps this is why I feel uncomfortable around people that seem good in ways that I cannot understand; it indicates a deeper self that I do not understand, cannot grapple with. </p>
<p>This is also the greatest tragedy in intimate relationships: we can see the surface, but anything beneath remains frustratingly opaque. We predict well, but cannot understand completely.</p>
<p>The fewer people understand something, the less likely it is to be challenged. This is the insidious invisible hand working against all academic knowledge. </p>
<p>Having the option to do something will change behavior regardless of whether it is actually done. Just having access to a phone changes how you think, even if you don’t use it. </p>
<p>Giving lasts. Altruistic actions have a much bigger psychological impact across time. </p>
<p>We are short-sighted. We want to get things done ASAP. What if aliens are wise enough to be freed from these human urges? Maybe we are the aliens - they send a microbe to evolve into intelligent life 4 billion years later. The idea of relational time; what really matters? How much time passes or how we perceive it? Do we need to feel bad for moths that only live a day? </p>
<p>We have the wrong idea. Why inhabit another planet? Real estate? The idea of real estate will be obsolete in 100 years. </p>
<p>Charlie Kirk has led me to realize the true value of fact checkers. Project idea/future tech to shape online discourse: fact-checking AI.</p>
<p>Any great scholar puts the truth first and everything else (their life goals, social justice) second. </p>
<p>Examine thoughts as if they are coming from someone else, not yourself. Examine them critically, give them a chance to be written down and examined. This is the basis of CBT.</p>
<p>Administrators are bloodsuckers. </p>
<p>The reduction of childhood to a sort of test prep.</p>
<p>Is there a qualitative difference that I can detect between older people and iGen? Is this why some people feel like adults and some not? Is this why I have a creeping feeling that everyone is a kid?</p>
<p>Cognitive behavioral therapy</p>
<p>Kinetic energy and internal energy the same thing?</p>
<p>We exist constantly in perceived relationships to things. That is how we define ourselves. <br />
There is no absolute global scope, but the more global a relational scope is, the more it takes into account relative scale. The more local a scope is, the more governed it is by our senses, or rather, the relationship between emotions and sensations. Different scopes also have radically different motivations, which motivate attempts to change our relationships with things. </p>
<p>Different scopes can have radically different personalities, because it changes the way we define ourselves. </p>
<p>The modern era has ushered in a time where our relational scopes can change immediately and frequently, without warning. </p>
<p>Meditation is a bridging of the most local and the most global scope. This is where people should be: able to access the most global (seeing things from above) and the most local (being emotionally "in-tune" with their senses: the base level of human existence. The madman smiles).</p>
<p>Global scope is your relationship with the world - all of it. This is an aspiration that is unfortunately not possible. The best approximation is relationships we have with the large. The deep. The big. </p>
<p>Seeing things at a global scale makes things feel small in comparison. It allows you to focus on the big things, because you can actually see them. </p>
<p>My superman is someone who has power over their scope of thinking, who can access both global and local. Capable people have a scope that extends beyond their daily existence; coders see at project scale, entrepreneurs see at company scale, physicists see at knowledge-base scale, the enlightened at some sort of transcendent global scale. They each see their relation to the big thing, rather than getting caught up in what's in-between: the mundane. </p>
<p>My scale is largely at the level of my own thoughts. The scope of my laptop. Very local. </p>
<p>In the scope of my life as a whole, what is this? What is a digital attention process? Nothing. </p>
<p>All of these scopes are valid; when you exist in one, your motivations adjust to what you see yourself in relation towards. </p>
<p>For you: social interactions should exist in a scope that encompasses more than the other person. Whenever you look at things in a larger scope, it gives you a chance to focus on larger things. To "not sweat the small stuff." I have a suspicion that this too will make you more capable, more emotionally resilient, and less stressed. </p>
<p>UW is an infinitesimally small subset of the total range of conscious experience. This is the realization that global scope yields. </p>
<p>Focus not on your relationship with people, thoughts, or things. </p>
<p>Focus instead on your relationship with the world. (truth, goodness, and whatever that may mean)</p>
<p>We exist in a near-deterministic relationship with our environment. We must structure our environment, both internal and external, to be conducive to our larger-scale wishes. Large must trump small, not the other way around. </p>
<p>What qualities are guaranteed to have impact? Not happiness, not thoughtfulness, but diligence. Always diligence. </p>
<p>Unfettered access to the internet teaches me to give in to random impulses. Searching up a phrase, for example, when without access this would have simply been a passing thought. </p>
<p>What makes something profound is an emotional impact, nothing more. </p>
<p>How do I make myself into someone who tackles hard things? Who is disciplined and future-feeling? There is only one permanent solution, and that is to become that person, to embody them. The initial justification might come from moral grounds, but any future motivation now uses the shortcut of identity confirmation. When am I going to take this leap? To become my own superman? </p>
<p>The unconscious is that which does not leave its mark on memory. </p>
<p>We don't know what's going on inside a neural network made to detect symbols, but then again, we aren't sure how our brain does it either. It just adapts and works. </p>
<p>You are obsessed with being the best to pad your ego, yet you aren't really motivated enough to go get em', to make yourself the best? Choose one, either one, (or both) to change. </p>
<p>It has become unfashionable to actually care about the things you learn in school.</p>
<p>Make some mantras as mental shortcuts. <br />
Social mantra. The mantra for elimination of social desire. </p>
<p>Bigness was not made for us. Vastness was not made for us. </p>
<p>Our emotional connection is to tiny, brief, fluctuations in the substance of the universe. Truly tiny compared to the vastness of the whole. This is our scale; one that we cannot escape. </p>
<p>My belief in the ultimate simplicity of philosophy gives me hope. </p>
<p>But perhaps it was not born to be so. </p>
<p>A new movement of simplicity.</p>
<p>Is there an inherent meaning in experience? Or is all value dictated by future permanence. If I have a profound thought but never think it again nor write it down, did I really have it? </p>
<p>4d fractal. We are not a “reading” along one dimension. Rather, motion is an illusion caused by memory. All there is is the “total being” along the time dimension. </p>
<p>The question is how dynamic, emergent experience (I.e things moving) can be generated by a totally static structure. </p>
<p>Then why do I experience the now and not the later? Why is there a now?</p>
<p>Collisions satisfy momentum and energy conservation equations. How does nature find solutions to these equations? As walter lewin says in Lec 16, it is amazing. </p>
<p>Take vitamin D supplements <br />
Minoxidil shampoo</p>
<p>Live in the future, then build what's missing.</p>
<p>Entre589<br />
Cse 589</p>
<p>Andrej karpathy</p>
<p>Mantra of equating the value of present and future. (mantra of utility-time constancy)</p>
<p>Ask yourself: If you had a magic wand, what would you like to see in your future? Ignoring the ideas of how you’ll get there, vividly imagine your ideal life, and what would be included in it.</p>
<p>Take a few minutes to list, on paper or on your computer, the changes and goals that would be included in this picture. Be specific about what you want.</p>
<p>A good heuristic for whether or not you should listen to someone: how often they raise their voice, and how negative their language is. How few questions they ask. </p>
<p>Go to where the smart (but perhaps not financially apt nor socially capable) people are. In the 1940s, smart people went to study physics. Now, where do they go? CS? AI? Probably where the financial incentives are. And the really smart? Where things are starting to get interesting. </p>
<p>Seward park<br />
Go arboretum via bridges <br />
Arboretum <br />
Golden gardens <br />
Ballard locks</p>
<p>How do constant changes in scalular perspective affect our minds? Moving led sign world. This scale affects the “background space” of conscious thought.</p>
<p>Sokal Hoax proves that it is possible for a paper to be published and deemed reputable without having been understood in the slightest. </p>
<p>What does a GEF (grand unified theory) look like? What is its form? Is it possible for one to exist?</p>
<p>It is impossible for a brain to continuously comprehend every part of itself, for the simple reason that a computer always has more information than it can store. The only brain computer that can store all the information about itself is the universe, where the state of the system is inherent in every particle.</p>
<p>Is the brain Turing complete? <br />
How can the brain compute things with just and and or gates?</p>
<p>Why evolutionarily do we have the need for instant gratification?</p>
<p>When we fall in love, who exactly do we fall in love with? A bag of common behaviors? A face? </p>
<p>Forgetfulness as an inescapable adversary. </p>
<p>What proximate things do I know FOR SURE have purpose?</p>
<p>The idea of purpose comes from desire. It is only from our human-desire perspective that things have purpose, like the roots of a tree (to sustain the tree throughout its lifetime).</p>
<p>The problem of motivation (sometimes called “alignment”) is the hardest problem to solve in the creation of an AGI. A system will never grow to surpass its own reward system (alphago will never write a book) yet giving it free reign on its own reward function will result in the reward system ceasing to have value (like giving citizens the choice to print their own money). Humans are smart because our reward system came preprogrammed to reward intelligent behavior (we just got lucky). </p>
<p>This alignment problem is not a problem yet because we don't yet have intelligent/independent agents. </p>
<p>Comfort is necessary for the choice to extraverse in the absence of outside pressures.</p>
<p>If sacredness can be captured in a form, who cares what form it takes?</p>
<p>Meditations/reflections on the nature and will of being. </p>
<p>Slow, intentional, logical, deliberate, individual side of me is a completely different side of me than social, habitual, impulsive, quick side. I cannot completely inhabit the first half unless I relinquish any thought of social judgement/visualization.</p>
<p>Core question: Are emotion and logic/thought parts of the same phenomenon? Reducibiliy?</p>
<p>Philosophy has been given a bad name by those who intentionally or unintentionally seek to obscure. </p>
<p>Emotion is the basest, most fundamental, most inescapable function of the human mind. The madman cannot walk, learn, or talk. But even the madman smiles.</p>
<p>The end of each day is a small death. </p>
<p>Morals are perhaps evolutionary pressures of a group on the individual? Like how worker bee sacrifices life. Or perhaps social pressures: constant invisible audience.</p>
<p>The moment you believe you have nothing to learn is when you stop learning. I can apply this to social situations.</p>
<p>Other people can change my neurochemical state for extended periods of time. Weeks to perhaps months/years.</p>
<p>Can curiosity be sort of killed by the feeding-content nature of modern education?</p>
<p>What does my Superman look like?<br />
Someone for which emotion and logic/knowledge amount to the same thing. </p>
<p>I have fallen in love with bodies, but never yet with a mind. </p>
<p>I am not able to relax among certain people because I subconsciously perceive them as threatening; to my emotional state, to my social status; to my self-esteem. This is not a useful perception. Downward social comparison is unhealthy.</p>
<p>When I have a deep need for someone to like me, it makes it difficult to be friends with them. Because I am afraid, at a subconscious level, of their power over my emotional state. I feel pressure that prevents things from flowing freely. </p>
<p>A suspension of disbelief. The operating scope of all philosophy is not universal. Pure skepticism is the only thing that is. </p>
<p>All other philosophy has to be, in some sense, applied. Applied to our lives, our senses, and our thoughts. It is no longer pure; it has been defiled by the needs of our human natures. </p>
<p>I suspect I was born in an era in which philosophy has been thrown by the wayside. And who can blame them? Everything is applied. </p>
<p>In philosophy there are only two questions. What is, and what is good. Everything else is irrelevant or a derivative. Existential/normative. The only pure existential philosophy is pure skepticism. Everything else is in some sense normative. </p>
<p>Some art has inherent, direct emotional effect: music, for example. Some is functional: architecture, public speaking. Most is what makes us feel smart and good about ourselves. This is the whole point of “subversive”, “thought provoking” art. </p>
<p>Functional<br />
Emotional<br />
Intellectual</p>
<p>Why = for what purpose, for what reason. We ask why to physical phenomena, as if there is a purpose, a reason, to them. </p>
<p>Why are research and teaching inexplicably linked, but only in a university setting? It makes no sense. </p>
<p>When self esteem is threatened, downward social comparison is more likely to occur.</p>
<p>It's a true shame that experience != wisdom. </p>
<p>The ultimate goal of my life is to be able to control my own mental-emotional state. To not need to rely on outside stimuli to change what I feel and think. This is the ultimate superpower. </p>
<p>Thought experiment with this superpower - what would you do if you had it? </p>
<p>Emotion overload more than information overload</p>
<p>Woe is he who falls in love with fantasies before people. </p>
<p>Writing allows a man to talk to himself in much the same way that a friend would proffer advice to a friend; from a perspective independent of the thought itself. It lends temporal stability to thoughts, allows one to reflect on something tangible, and relieves the difficulty of juggling both the reflection and the subject. </p>
<p>"I generally try not to be logical when it comes to dating someone initially, it’s easy to fall into analysis paralysis. Trusting my instincts and having fun while not making anything serious the first couple dates works for me. After three dates, then I usually start to consider if there’s any long term potential and be logical."</p>
<p>----------------------------------- start of different chronological order: new thoughts up top</p>
<p><strong>The inherent “self” remains logical and relatively unchanged. But the social constructs we create are pulled to fill roles, niches, in our community. Thus they change constantly. Many of our external attributes are not as a result of internal logic, but to fulfill the goal of a coherent and more interesting persona. Thus the idea of “self” is split.</strong> </p>
<p>Journaling </p>
<p>Prehistoric sleep schedule experiment</p>
<p>Experience vs memory: is it worth it to take a vacation you won’t remember?</p>
<p>Open letter to whole grain mustard </p>
<p>VR is the future - advancements:</p>
<p>Smaller headsets that look like glasses that cover your eyes: cameras in them so you can have incredible vision- LEDs in front so you don’t look that weird - worn 24/7, will be the norm for you to not take them off - you can’t live without them - will be easier to fix problems in VR than in real life - blurring with reality - we need a good grasp of what reality looks like right now.</p>
<p>How I stumbled upon this thing : tried VR for the 1st time.</p>
<p>Spotify usage</p>
<p>Stock market is dumb - share price isn’t inherently tied to anything if no dividends </p>
<p>What are the chances that you are here, in this body, right now? 1 in infinity or 1 in 1?</p>
<p>Project:</p>
<p>A defense of psychological egoism and it’s implications</p>
<p>No free will?</p>
<p>Preferences are beliefs?</p>
<p>Conscious vs unconscious choice - max happiness rule dictates conscious choice </p>
<p>Bliss paradox</p>
<p>Criticism of utilitarianism</p>
<p>Informational ethical normative theory</p>
<p>Common criticism: PH says all forms of happiness are the same</p>
<p>Wrong, but they can hold certain values and be equated</p>
<ol>
<li>Uniqueness</li>
<li>Counterexamples</li>
<li>Strengthening</li>
<li>Resources </li>
</ol>
<p>Science in a democratic society</p>
<p>Existence cannot be used as probabilistic justification</p>
<p>On meditation:</p>
<p>Is there an unchanging “buddha nature” behind our single-threaded monkey brain?  </p>
<p>Unawareness of thought is fundamentally indistinguishable (from self-perspective) from absence of thought. </p>
<p>The idea of living in the present is linked with the idea of self-awareness, yet to be self-aware in a linear single-threaded consciousness is to reflect upon the mind-state of the immediate past. So is living in the present really simultaneously possible with self-awareness?</p>
<p>The mind as an operating system. </p>
<p>My “feeling” of happiness are fundamentally incomparable with your “feelings” of happiness. Emotions are not a byproduct of the motivation system. They are the emotion system.</p>
<p>Does constant access to information diminish curiosity?</p>
<p>Does anger pay?</p>
<p>We are constantly trapped chasing this arbitrary thing</p>
<p>To be in control is to control your happiness system.</p>
<p>The universe is just senses</p>
<p>The world is far too complex for any one person to understand, because of the immense abstractions and complexity we have built for ourselves. This necessitates the ability to focus on a specific niche without understanding details of the entire system. Modularization, in other words. </p>
<p>We can’t communicate emotions</p>
<p>Universe fractal</p>
<p>Is it better to throw away 5$ or 5$ worth of tomatoes?</p>
<p>Reading books is by far the most efficient means of information uptake. Reading anything, anything at all, is more educational than going to school. The problem with school is that it fills free time: instead of reading, we are doing homework or doing things to distract us from doing homework.</p>
<p>Vast formless things. Don’t get mad at the puppets.</p>
<p>The incentive, reward system, and behavior comes from larger-scale contextual framework. Awe, ‘the sublime’, comes from a massive framework. </p>
<p>The body is a subset of the mind. </p>
<p>Ive been conditioned after years of upbringing and schooling to not be able to identify clear priorities, or have split priorities. Everything seems important: I have to bee good at everything. In reality, one thing out of many is 1000x, and everything else is a waste of time. </p>
<p>Logical motivation is temporary and easy to ignore. Emotional/pleasure based incentive is always there and much stronger. That’s why you have to like the things you want to do. Self control is prioritizing logical motivation.</p>
<p>Maybe productivity, efficacy, and bravery (having the initiative to do things immediately - no dread) are products of the removal of self? “I don’t care what happens to me - there is no ‘me’.”</p>
<p>If you are happy you are more wealthy than the richest billionaire.</p>
<p>We see things very linearly. One action can be 2x as useful as another. Chopping wood for fire vs hunting game: the hunter gatherer mindset. Tech has the effect of selective exponentiation: to survive in todays world, you need to be able to see a sense of scale that is not built-in. Most actions are useless: they have no future returns. But some, just some, have 10x and 100x and 100000x impacts - they can set your life in an entirely different direction. The key is to see the raw scale and then to find and exploit those actions.</p>
<p>Oversaturation is the largest problem facing youth today</p>
<p>Dystopias are not dystopias</p>
<p>Key skill for the future: dealing with abstraction </p>
<p>Sometimes the key to doing something is wanting it badly enough. The problem is that knowing this fact doesn’t allow you to adjust what things you want - you can’t choose to want something just because you want it.</p>
<p>Everyone is a dream. A refraction of the self. We interpret and reinterpret, not realizing that we can never see even a fraction of what is real. </p>
<p>The more I think, the more confusing things get</p>
<p>Are illusions of inflated scale inherently bad? MTG</p>
<p>Everything is equally real</p>
<p>If you view love as a game you will always lose.</p>
<p>Being at one is a matter of context</p>
<p>Anthropic principle/grabby aliens. Way to explain the eventual/inevitable adversariality of AI? Sounds fishy</p>
<p>A lot easier to create VR than RR. Taking over space will be robots. </p>
<p>In any virtual reality it becomes trivial to create infinity. </p>
<p>Good centered around true perception of reality. Maturity, seeing the bigger picture</p>
<p>The benefits of being totally, brutally honest: It’s easier. </p>
<p>reality</p>
<p>You ARE the creator. Religion</p>
<p>We only have one global maxima. Beauty, for example. How is our brain structured like this? What do neural nets have to learn?</p>
<p>Programming provides an easy interface with the virtual infinite.</p>
<p>I’m just a normal person with illusions of grandeur. There are plenty of those out there. </p>
<p>I hate how fallible my memory is. Suffer from last impression phenomenon. That’s why I hate it so much. </p>
<p>I live in a constant psychological hell. The only distraction is being among others, which is maybe why I do it so well. </p>
<p>One thing different about writing and thought is that the confidence level for each statement in writing is very coarse. Discrete vs continuous.</p>
<p>I have a bird’s eye view into the workings of the mind. Maybe this is a unique place to be. </p>
<p>Modernity:</p>
<p>You have no time to read, and to think. You have bigger matters to attend to.’</p>
<p>The world needs more children’s books for adults</p>
<p>Dissociation of beliefs in politics is good. Inverse is true.</p>
<p>The biggest thing affecting behavior is how you see yourself. </p>
<p>We like people with contrast in their traits. Maybe connected with the role of contrast, unexpectedness, in humor. </p>
<p>My biggest problem with self-learning: avoidance due to feeling dumb or slow or not able to understand immediately. Lectures, even though they are slower, solve this problem by giving me required time to think. </p>
<p>Get better than a minute per line of code</p>
<p>When we grow, we become more and more lost. </p>
<p>Psychological hedonism stuff</p>
<p>Stock market - no intrinsic value. The emperor wears no clothes!</p>
<p>Entreprenurs manufacture a scarce and desirable asset called “stocks” not unlike cryptocurrency or gold mining. They add more wealth by creating it then selling it to others. </p>
<p>Belief credence/weight. Most have none, even though we are exposed to amultitude. </p>
<p>The sci-fi reflex: the chills we get from seeing into an unfamiliar future world. The “that’ll never happen.” The truth is, we already live in that world.</p>
<p>Humans are emotional amnesiacs</p>
<p>Insight + memory -</p>
<p>Whether or not something is original has nothing at all to do with whether it is true. </p>
<p>Philosophy, like physics, explodes in complexity. Is this necessitated by the hard paths of logic, or is it a false creation?</p>
<p>There is no inherent up and down<br />
Thats how shackled we are to our perception minds</p>
<p>We give a lot of credence to ideas because they are old. <br />
Meaning less survive. Meaning they are scarce. Plato’s allegory of the cave would not aurvive today.</p>
<p>What does it mean for something to "make sense" and "not make sense"? Some explanations "don't make sense" and are therefore invalid.</p>
<p>Does the fact that I was born right now, in today's world, mean that the human population will not grow into the trillions? It would be highly unlikely. </p>
<ol>
<li>AGI will not align itself to our values. There will be no AGI as a tool for human progress. </li>
<li>This is not a bad thing. </li>
</ol>
<p>Lack of information about the future scales exponentially, just like the possibility space over time. </p>
<p>We cannot dream of things 100, much less 200 years in the future. </p>
<p>Human psychology is fundamentally unsustainable and unfit for the future. </p>
<p>Nothing about the nature of consciousness necessitates human identity. </p>
<p>The internet means constant subjection to hooks that can pull our attention away from intention. Command line interface - only exposing the parts that are specifically asked for - solves this problem. An interface should not present more than it needs to. </p>
<p>People love predictable personalities</p>
<p>Bottleneck of societal progress is not lack of information but lack of effort. All we can do is bring the threshold down, or the effort up.</p>
<p>Within a year, chatGPT has gone from completely impossible to completely accepted. It’s astonishing.</p>
<p>We cannot hope to raise our standard of living. I desperately hope, like -the guy that predicted we would starve due to overpopulation-, I am proven wrong.</p>
<p>We live in a world oblivious. Everyone has a library in their pocket.</p>
<p>The reason occam's razor works is because it opens up the minimal surface of attack from discrepancy and logical contradiction. </p>
<p>Is there some logically rigorous way to approach the predicted expansion of physics? Is it possible that there is no unified theory? Is it possible for a model to be infinitely complex? Is it possible that our universe is not bound by a consistent set of rules? Is it possible that our universe IS bound by a set of consistent rules? Proof by contradiction?</p>
<p>What is a set of consistent rules? Do we want to find one? Supposing we do, what will our meaning become? If there are fundamental limits of knowledge.</p>
<p>Only display to the user the parts of the tool that are truly essential: the ones that create a minimal application. Further on, allow the user to allow new features themselves. Out of sight, out of mind. </p>
<p>Metaverse will never become as immersive as real world, simply because real word utilizes all matter for computation vs just the atoms in a sillicon chip.</p>
<p>TVFA will be unbelievably sparse. I will have explored maybe 0.01% of the graph space. </p>
<p>At some point my obsidian vault will be the most valuable thing I own. </p>
<p>Working as a protocol. Always finish initialization function, then move on to the non-blocking stack of functions that were called. Stop at some point, but prioritize perishables. </p>
<p>The huge scaleables (moore’s law style tech) will be the jumping off point for the truly world-changing technological innovations. Clarke showed email, but he didnt invent the connected PC.</p>
<p>Having fulfilled our most basic needs, where will tech go from here? Will we stagnate? </p>
<p>The reason that humans keep on living is because we have a reward system that we cant change- that is biologically engrained within us.</p>
<p>This system is unobjective. </p>
<p>When we construct a smart machine that can make its own mind, what happens to the reward system that motivates all behavior? What is it motivated to change it to?<br />
Recursion results. <br />
Undefined behavior- perhaps apathy.</p>
<p>Maybe the reason we are going to dominate over machines is that we are less powerful over our own minds. We are hard coded.</p>
<p>Everything, including ourselves, are machines.</p>
<p>What role does the reward ststem play in true intelligence? Can one be intelligent without being motivated?</p>
<p>By exposing the deepest parts of yourself to the public, you become less vulnerable to attack. Why? Because asymmetry of information is viewed as such a potent weapon. You induce symmetry, and thus remove leverage. </p>
<p>We probably lose a lot of "student-ness" when we become teachers. How else to explain how bad some teachers are?</p>
<p>Religions are composed of cultural practices much more than beliefs.</p>
<p>My ultimate calling may be to study the nature of mind, and the idea of AGI. <br />
A combination of psychology, philosophy, computer science, neuroscience. <br />
Take OS course<br />
https://en.wikipedia.org/wiki/Computational_theory_of_mind<br />
https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence<br />
https://en.wikipedia.org/wiki/Wirehead_(science_fiction)<br />
https://www.hedweb.com/hedonist.htm</p>
<p>Innovation and discovery come on the edges. As the circle widens and becomes treacherous with complexity, it's harder and harder for someone originating at the center to make it. </p>
<p>In society, people are either miners or crafters. In an age of plenty, crafters dominate.</p>
<p>Rest may be overrated. Meaning improves focus and energy much more than rest does. </p>
<p>He lived in virtual worlds because he didn't want to grapple with the hard questions of the real one.</p>
<p>We believe most strongly in the things that other people don't. </p>
<p>Perhaps my insight into my own mind was honed by the soul-searching and intense questioning I did as a child in response to depression. </p>
<p>Lack of memory renders you unable to learn from your own mistakes. </p>
<p>External: physical. Internal: intelligence.<br />
Physics/astronomy/chemistry VS AGI<br />
Areas of study</p>
<p>Experiences, thoughts especially, may seem profound and affecting at first, but seldom do they escape the amnesia of time and the return to background of habitual thought.</p>
<p>Thus, the wisest arent necessarily the ones that have the most experience. They are the ones that can control their background and apply through time their temporal observations.</p>
<p>Experience and insight does not mean good or more profound or more wise or more learned or better personality. </p>
<p>Once a musician makes a sound its no longer theirs.</p>
<p>Lack of intention is perhaps the root of the problems created by the difital age. Easy access to information means we access it absentmindedly</p>
<p>I worry too much about the nature of things and not the function of things. </p>
<p>God provides an interface - a human, relational way of communication (devotion is the inevitable state of this relationship) -  with the things that are unimaginably larger than us. Thats why god is such an atteacive idea- we know we want to worship something larger, “everything’, but cant unless that thing is personified.</p>
<p>God is useful because it provides an outlet for thankfulness- gives us someone to thank for everything. This is thankfulness inducing.</p>
<p>Infonite happiness promise 1% religion death.</p>
<p>Maybe its better to do only 1 or 2 things a day. </p>
<p>A trillion dollar problem: how to give the most capable the most say in decision making. Related problem: how to identify the most capable</p>
<p>Unfettered exponential growth is the scariest thing in the universe.</p>
<p>Physics as constant and universal, vs physics as a dynamic, chaotic, and infinitely complex system, like life. Like the earth before and after life. The genius of cixin liu.</p>
<p>Maybe the singularity in BH is one dimeniosnal- like cixin says, the three dimensions get collapsed into one (or two) in the inescapable bubble. Essenially the one dimensional singularity contains the entirety of the three dimensional volume. Space turns one dimesnoonal within this bubble. Is it possible to collapse dimesnions down while presercing quantum information?</p>
<p>Sci fi employs hyperdrive not to keep the passenger from experiencing time, but to keep the outside world from experiencing it</p>
<p>You spend a third of your time working for the government if you make 200k</p>
<p>I can't seem to make things last because my world isn't stable. It doesn't have the constant truths that anchor others. I get lost in my mind and glimpse many fleeting truths that are with me for an instant, then get blown away. In this environment, I come to the conclusion that I know nothing, am nothing, and the things that comprise me are scattered- fundamentally and irrevocably scattered, the one-sided door of entropy, if such a thing exists.</p>
<p>In splitting attention I live a half-life.</p>
<p>I live a half life.</p>
<p>I live a half life. </p>
<p>Writing as a form of thinking, much like the solidifying power of explaining something yourself.</p>
<p>Perhaps AGI research, the philosophy and theory of mind, etc. caters well to my skillset. I am reflective, insightful, and like solving hard problems. </p>
<p>The notion that AI is creeping closer to human intelligence lends much to the realization that humans are much more like automata than anyone had imagined. </p>
<p>I love what I don't have, and hate what I do have. </p>
<p>I'm biased towards people who have personality traits that I don't have. </p>
<p>Poor people play a very important role in society. Rich would not exist without poor. They are indispensable. The poorest of today are richer than the richest 1000 years ago, but it is the psychological discrepancy between well-off and poor that creates the economic environment we see. </p>
<p>Human psychology like a physical system- always approaches a low energy state without outside disturbance.</p>
<p>Directionality sense of direction absolute initialization</p>
<p>The predicted reward system function is the integral of the self-control function over time (how much you prioritize now over future.) Truly greats have a constant self control func over infinite time, not possible in reality because integral over infinite time is infinity.</p>
<p>Two spies isn't a successful game because of its discreteness.</p>
<p>I get discouraged because of the infinite imperfect complexity of fields. </p>
<p>The process of wrestling concepts into the submission of understanding is difficult and often unpleasant, mainly because I am uncompromising and rigorous. This provides me with an "all or nothing" advantage of full understanding. </p>
<p>My unique reflective insight into my own mind provides me valuable information for fields involving the nature of thought. </p>
<p>A certain sect of the population must be poor.</p>
<p>It is the fundamental goal of the tireless march of history - wars, revolutions, governments - to decide who this sect shall be. </p>
<p>Subsocial identity formation: we always form our perceptions of ourselves from the perspective of others. The observer becomes different from the observee. Just the act of observing implies an "other."</p>
<p>The answer to the question of consciousness is that we aren't conscious. </p>
<p>The sect of people that are both truly bad and truly smart is probably smaller than we think. It's possible that intelligence and morality are correlated. This might protect us from apocalypses, as long as number of individuals and impact are roughly linearly correlated. </p>
<p>My two areas of interest:<br />
Philosophy of mind/AI, AGI development<br />
Metaverse, AI based movement tracking, etc. </p>
<p>Any data that a psychologist aquires has been filtered through a layer already. THere is no perfectly pure observation. The bottom layer of purity in data collection is only inhabited by one person: the psychologist himself. This makes it difficult to generalize. </p>
<p>The idea of being a being separate from your thoughts arises from an attribution filter wired deep in your unconscious. Single threadedness prevents true seperation. Same mechanism creates personality disorders. </p>
<p>If I have one firm belief about philosophy, it is that terms need to be more rigorously defined. </p>
<p>Time erases 100x more than we believe. It erases everything. The only way it influences experience is through the scarce thoughts that rely entirely on memory. For each memory, there are probably a single-digit number of thoughts regarding them in a lifetime. The other 90% is killed, reborn, every second.</p>
<p>Is there any way to reliably tell if a robot with full control over their appearance (in contrast to humans) is benign or merely pretending to be? No. Therefore, it becomes dangerous to put any “intelligent” entity in a place of power.</p>
<p>Mind reading creates hivemind.</p>
<p>Is outlook/attitude intrinsically tied to information? Two people, with precisely the same information- is it possible for one to be happy and the other sad? If no, does it imply an objective emotional state for each informational one? Can a happy person comfort a sad one just by presenting evidence? Can all arguments/differences in perspective be boiled down to a discrepancy in information? Information includes both evidence and internal, temporary beliefs, like “people are intrinsically kind “. Does this question even have meaning?<br />
This question equates emotion with truth.</p>
<p>My belief is that philosophy should be laid out in a fashion so obvious, so straightforward as to be almost trivial. That is the only way to ensure a coherent line of reasoning. </p>
<p>Too much philosophy is obscured behind a deep layer of ambiguous, wordy description, to disguise simplicity or perhaps lack of clear reasoning.</p>
<p>Is this necessary to cover the distance of the edge of philosophy to the layman’s origin?</p>
<p>Try explaining humor to an alien</p>
<p>Why are you watching someone talk about it? Just reason about it youself!</p>
<p>Find some words for this: enlightenment, annihilation. The realization, past the mask of senses, of a truth unimaginably greater than any thing heretofore perceived. True truth. True scale.  The only thing preventing me from true annihilation is the limited size and scope of my mind. </p>
<p>It is my firm belief that there is a true reality far more wondrous in every single regard than the mundanity of daily consciousness. Perhaps it is an admittance of our own cognitive limitations to think this way, but I think our senses and thoughts encompass a tiny fraction of what IS. This is a fundamentally optimistic creed: it recognizes that there is more to see. Some examples of more-ness:<br />
Perhaps I am just a tiny part of a huge process of evolution on a cosmic scale. All tomorrows. <br />
Perhaps what I can see is only one fraction of the range of human experience: being, remembering, feeling the feelings of all places at once, both memory and imagination. <br />
Perhaps the laws of physics are a work of divine complexity beyond human imagination, and perhaps they are shaped by higher powers (three-body)<br />
Perhaps I inhabit a world with infinite detail. <br />
Perhaps there is no good. <br />
Perhaps I don't know. </p>
<p>This is a philosophy that is humble. The only thing I know is that I know nothing. </p>
<p>Psychedelics perhaps temporarily increase the realization capacity by creating more connections between different parts of the brain, bypassing biological restrictions. Maybe this is a closer view of reality. </p>
<p>Science and philosophy have the same goal: the transmutation of suspicion into logic. </p>
<p>I don’t read things that I agree with.</p>
<p>Key values of the new school:<br />
Seeing scale. Seeing place in whole. Seeing reality at the largest scale constitutes enlightenment.</p>
<p>Oh what I would pay for the internet: infinite knowledge, infinite entertainment at my fingertips, written just for me.</p>
<p>Something modern media, cancel culture, does not realize: there are no good people and bad people. In a hundred years, maybe 90% of us will be considered “bad” by the standards of their time. It is hypocritical to assume otherwise. The idea of “good action” is a constantly rising tide.</p>
<p>You can’t do anything about dumb humans. But you CAN do something about dumb computers.</p>
<p>It is a curse to be able to fall in love with stupid people.</p>
<p>As our :technological: power increases, so does the necessity to understand what actions are good and which are bad.</p>
<p>I support AGI because more knowledge will help us (or someone) solve more problems, including moral ones.</p>
<p>Two schools of aging: <br />
1. Evolution “lets go” after reproductive age, letting loose ends fray and fall.<br />
2. Evolution has deliberately programmed obsolescence into our bodies to give more tribal resources to the younger generation. A form of genetic altruism. </p>
<p>Present absolute utility. All our decisions are shaped not on maximizing our happiness in the future, but by maximizing our happiness in the present. We are merely a gradient descender in an endlessly shifting cost function. Every single facet of human civilization has been produced as a side effect of this unchangeable biological force. </p>
<p>This is the core principle: the base model of all human behavior. Without it we cease to exist. We cannot change the behavior. We can merely alter the landscape. </p>
<p>This is the endless Sysyphisian existence envisioned by Camus. Constantly pushing up the hill. </p>
<p>Beliefs shape the happiness we feel in the present - they shape what decisions give us the most joy. This is the basis of all consciousness. It is the kernel of our operating system. </p>
<p>How else would we be able to choose things? How would our brain do it?</p>
<p>Biology provides us with ways to shift, to adapt this cost function via beliefs. The cost function is no longer a perfect evolutionary proxy. </p>
<p>"When a measure becomes a target, it ceases to be a good measure." </p>
<p>The reason we are bad at predicting our future happiness after doing certain things is because our biology is constantly trying to subvert this phenomenon. </p>
<p>Physical intimacy as a substitute for mental intimacy. </p>
<p>Restrict dopamine release until having done the thing, not having resolved to do the thing. </p>
<p>Might vs right is a version of us vs all.</p>
<p>People fear god because it is easier to fear the definite than the indefinite, and there exists no more definite a fear as the wrath of a man.</p>
<p>Philosophy is often criticized for being untestable. Is mathematics testable? </p>
<p>The prime driver of the development of masculinity is a yearning for female attention. Women control the idea of what is masculine.</p>
<p>The only true emotions (verticals) are happiness and sadness. The others are mere thoughts, mere patterns in the cost function. Anger, jealousy, and lust are all forms of intense desire. </p>
<p>Why should I feel good about myself right now? I know full well that I have been unhappy in the past, and will be in the future. Am I wiser now than I ever was and will be? If not, what right is it if mine to be happy? Why not listen to those wiser than me?</p>
<p>The model of the rational arguer - the one who vbelieves something only to the extent that they can argue it- the one that argues not to convince, but to exchange, and the one that does not hold deep-seated beliefs that cannot be touched by opposing rationality - will soon come into vogue. If I become famous, I will make my beliefs public, but open to arguments in search of truth. None of my beliefs will be invincible.</p>
<p>Coding is not about the code. It is about reading comprehension. It is about having the imagination to hold complex structure in your mind. When you think of code, you should not think of lines. Just like when you think of a book, you do not think of the individual printed lines. You think about the characters, the plot, the feeling, the universe the world builds for you. The same is the case for code. Do not regard coding as syntax. Regard it as the construction of imagined structure. </p>
<p>Code is merely the incantations you utter to cast a finished spell. </p>
<p>The culture we understand is the culture of a tribe. This is what a "vibe" is. This is the "vibe" of a book. Three body problem had a different vibe from the secret history and from groundhog day and from annihilation. A vibe is a complex feeling that exists by virtue of its balance of  different envisionments - places, smells, colors, people, fashion, all facets of culture - to be independent, to harbor the impossibility of mutual coexistence. We can only imagine one "vibe" at a time, which is the simplification of the culture of a tribe. This is why alien movies (or any movie, including the simstim of conscious experience) will always fall short of true reality. Presumably, an advanced alien civilization has as many facets of culture as we do. But we only get one "vibe" from a book or a movie. </p>
<p>A noble goal: to wrest time away from impulse to thought. To revolutionize the way we interact with technology. The only things that the user should see on screen are the things that they THINK about using. What is the word I'm looking for? Conscious purpose, direction. Deliberateness. </p>
<p>The omnipresent narrative of inherently unequal power dynamics allowing people to be "taken advantage of" deprives the victim of free will. </p>
<p>Social pressure is the strongest form of silencing. We need more people that can prioritize truth over fitting in. People that go against the grain, not as a hidden pursuit of social gain, but because that is what is right and true. People that are not afraid of being distanced, shunned, or snubbed. People not afraid of hurt feelings or egos. People willing to challenge the social norm. </p>
<p>Strong altruism is a flavor of self control. </p>
<p>One of the tragedies of college is the separation, within a class setting, of content and character. Professors should start with a lecture about themselves, talking about their research, some anecdotes, things they find interesting, and so on. </p>
<p>Tomorrow is tomorrows tomorrow.</p>
<p>Procrastination is not as much the avoidance of action as it is the avoidance of thought. One is much more easy than the other. </p>
<p>There is no “I’ll do it tomorrow”. There is only “I do it now” or “I do it in a long time, once somehow the urgency of the situation breaches an arbitrary point that I will leave up to chance, possibly never. “Tomorrow” is merely an illusion to make the second option easier to swallow.</p>
<p>The problem in modern philosophy is lack of conviction. We have lost our way. All great philosophers have believed their theories entirely, and have been able to back them up. Now we live in an era of tolerance- many theories are correct in their individual ways. Modern philosophers do nothing but study the greats. No! We must continue our search for truth.</p>
<p>I am not my thoughts. </p>
<p>Microthink inefficiencies optimization.</p>
<p>I predict the death of symbolism</p>
<p>There are 2 kinds of understanding: the understanding of how to shift your cost function, and the understanding of which actions will maximize it. </p>
<p>Knowledge IS the least-energy state of computation. Knowledge is the most cost effective way of understanding how to solve a problem. </p>
<p>To be more specific, knowledge is the most efficient valid isopomorphic mapping from observed structure to structure. Proof of Occam’s razor?</p>
<p>Aimlessness is the ultimate evil. If you don’t know what is good, the worst possible thing to do is to not do anything about it. First priority should be to define explicitly what you intend. The world is filled with evil. Schools should first think deeply and hardly about what it means to educate before they take an attempt at it. The search to find an aim is the precursor good.</p>
<p>Whether or not something is original has nothing at all to do with whether it is true. </p>
<p>Philosophy, like physics, explodes in complexity. Is this necessitated by the hard paths of logic, or is it a false creation?</p>
<p>An aligned AGI is inherently impossible, assuming AGIs have free will. </p>
<p>The only way to save ourselves is like the black hole in the dark forest. </p>
<p>Leftover ported from notes I forgot about:</p>
<p><strong>Perhaps is is not the lack of individual innovation that is the limiting factor to human progress, but the lack of innovative education. Or the lack of effective communication.</strong> </p>
<p>Mistakes are the price you pay for greatness. And it’s a steep rate.</p>
<p>The problem with effective government: it is impossible to consistently create a leader that is benevolent, intelligent, and strong. </p>
<p>The important thing is not the content so much as the concentration: the single-minded deliberateness you must embody in any task. Do NOT do more than one thing at once. That is the golden rule. If you are going to be distracted at least put your heart in it- do not try and convince yourself you can do more than one thing at once. </p>
<p>This is what people don’t realize about our modern digital era- meaningful understanding doesn’t come from the volume of information processed. It depends on deliberate, purposeful, and distraction-free thought. Depth needs not scale, but emphasis. Energy. No wonder we lack meaning- our devices connect us to infinite paths of extraneous thought. But they cannot endow us with more effort. 2:29 PM FEB 11</p>
<p>“Do the creators of the universe create the laws of logic, or merely obey them?”</p>
<p>“Treat me like an adult, I will be an adult. Treat me like a child, and I will be a child”</p>
<p>“The worst crime is to explain something you do not fully understand as if you do understand it”</p>
<p>Corollary:</p>
<p>The difference between visionary and normalcy is not what thoughts you think, but which ones you emphasize. Feb 3 6:34:35 PM</p>
<p>It doesn't matter how many thoughts you can think, but which ones you can EFFICIENTLY link together in cohesive arrangement. An unnoticed thought is a dead thought. This is why it is possible to have a vast field that is still stagnant. Philosophy, for example. </p>
<p>The greatest power you can have is over your own mind. That is how you change the universe. </p>
<p>We can learn as much about the universe from psychology as we do physics. </p>
<p>The fundamental problem of memory: we know nothing about the reality of our past mind-state. All we know is how we remember it. People say that the “flow state” makes time pass quicker, but this is fundamentally indistinguishable from the possibility that the “flow state” just makes our memories of the state faster. Past experience is indistinguishable from the effect of memory. You cannot say that you had an experience - you can only say that a memory exists of this experience. We know as much about our mind-being in the past as we know about the mind-being of other animals. The now and the past are fundamentally separate. Thus, we are a fundamentally different person from ourselves five minutes ago - our consciousness is as separate as of that which is between people. 9:25:55 Feb 7</p>
<p>Corollary: </p>
<p>We cannot understand emotions other than those contained in our current mind-state, except by referring to our flawed memories. This is why it is possible to be deeply depressed and rapturously elated in the same lifetime. This is also why absolute empathy is impossible, even for a past self. If it were possible to re-experience memories in a perfect state, we would constantly find ourselves reverting to the emotional states of past memories. Instead, our current emotional state is a biased lens through which we view memories: when we feel sad, our memories seem sadder. When we are happy, our memories seem happier. </p>
<p>The role of memory. Feb 2 10:51 pm</p>
<p>The future is now. We just don’t see it like that. Feb 3 3:55:58 pm</p>
<p>The first step to finding a useful solution is to notice all problems. How could they be solved? You have problems. Why can’t they be solved? How would they?</p>
<p>Only 5% of your “working” actions are meaningful. The rest lead nowhere. The paradox is that you can’t identify which of these actions are meaningful while in the act of working - you need to take a step back beforehand and map out a series of actions, a plan, that will achieve the current problem (scope 5 mins to 2 hrs). The rest is just floundering about. </p>
<p>Distractions emerge. I have started to notice them. Use temporary mind-computer command storage to eliminate these derailings. This is the value of introspection. This is what you do when you meditate - you notice your conscious state of being from a third person perspective and have power over it. You can control distractions that you wouldn’t even notice otherwise. This is also what you use to make temporary plans to increase productivity. You view it from afar. </p>
<p>Education is temporal communication. Passing knowledge along generations. </p>
<p>Individuals are way stupider than societies. How can we build huge structures when the individual is so stupid? How can we have made it this far? It is communication. </p>
<p>To be a true visionary you need to know when to disconnect 8:08 Jan 31</p>
<p>The difference between visionary and normalcy is not what thoughts you think, but which ones you emphasize. Feb 3 6:34:35 PM</p>
<p>It is human nature not to be satisfied. How can we, if our brains are wired to do one thing, and one thing alone: seek pleasure? 8:17:43 Jan 31</p>
<p>On the modularization of thought pattern and how to work a stressful job.</p>
<p>Schools mimic the “BS” job creed that grips our culture- better to be doing a meaningless job than nothing at all. This is the unspoken violence committed agains our children- that this creed is constantly engrained where time is spent filling out meaningless paperwork (worksheets) </p>
<p>On our relationships with the high status:</p>
<p>Default behavior is envy, resentment. But the tiniest bit of reciprocal respect - one glance, one interaction, one smile, can radically shift our views about them from resentment to admiration. This is why celebrities are so often villainized or idealized. Their status acts as a multiplier for our opinion. Their multiplier is higher - they can easily endow us with unimaginable status, or by dissing them we can achieve status ourselves. This is why we develop strong opinions about people we have never met, that we will never interact with. Tue Jan 31 2:48</p>
<p>An interesting thought regarding responsibility, causation, and chaos theory. 6:35 jan 31<br />
If butterfy effect is real, any action will have multiplicative/exponential effects that will change the course of history. Whether or not it is changed positively or negatively is essentially random. So what is the individual responsible for?</p>
<p>Social side of personality vs “alone” side</p>
<p>On the emergence of bureaucracies: misaligned economic incentives. While big boss wants profit, the people he employs naturally just want status, ease, and money. Time-based payment makes no distinction between real work and just seeming to do work. Since seeming to do work takes less effort, employees do it. So too do they hire underlings with meaningless jobs - it gives them status to boss people around. It makes them seem like they are doing work, contributing even, when huge pockets of the structure are cancerous - they have no other meaning than self-preservation. Thus, they naturally spring up and stay there.</p>
<p>This is why even in a capitalist society, economically and personally meaningless jobs are so prevalent. The work doers are payed just as much, or less, compared to the work don’t-ers. The create-more-work-to-self-preserve-ers.</p>
<p>People that buy into these meaningless jobs are people that need money. The money flows freely because of bureaucratic inefficiency. Thus, the system is self reinforcing - the ones that need money are the ones given worthless jobs. The worthlessness ensures that the only work being done is work to self-preserve or go up the corporate ladder. This is why corporateness is so ‘boring’: free thinkers don’t have the obedience or patience to sit and do meaningless “work.“</p>
<p>It’s easier to put in the time than to put in the effort. So why are we still paying based on time?</p>
<p>Just as a coder who is paid based on the number of lines they write will write bloated code, an employer paid on the amount of work he <em>seems</em> to do will create a bloated bureaucratic structure. </p>
<p>Corollary: </p>
<p>The most efficient companies are the ones that have personal economic incentive directly linked to company incentive. The ones that don’t create bullshit jobs. The ones whose CEO doesn’t employ people for the sake of being an employer. The ones that have the flattest structure: like a pancake, not an onion. The ones that don’t leak money from misaligned pipes.</p>
<p>End of notes doc copy</p>
<p>You grow up when you realize that some mistakes are irrecoverable.</p>
<p>I will give no heed to thoughts I cannot articulate.</p>
<p>If you want to get multiple things done, carve out a part of the day for each one where you cannot do anything else.</p>
<p>Do things before you talk about them. </p>
<p>I've cultivated a personality that is typical here in college. Bad idea mate</p>
<p>Talk less, DO more. DOING things is where you will meet people interested in the same things as you are. That's where you get cool people. </p>
<p>A constant critic. You are destined for greatness, and what you are doing now is not good enough. No matter what, you are not doing enough. </p>
<p>I am an introvert that is great at acting like an extravert. This is unsustainable. </p>
<p>[[Tendencies that don't serve me very well]]</p>
<p>Subtlety: the complexity of the isomorphism needed to extract meaning from a medium. E.G. the size/complexity of the decompression algorithm. The more random the message looks, the “subtler” it is. In humans, this means having the so called “experience” needed to decode a message. E.g non-obvious. </p>
<p>Even though this is the opposite, in a way, of knowledge path as an efficient isomorphism. Why we don’t want our math textbooks to be “subtle” but want our art and music and food to be is a little beyond me. I think maybe math is inherently challenging, while the others are not. They need subtlety to be satisfying. This is also where humor lives. In the in-between of confusion and obviousness- “ohhhh, I get it”</p>
<p>The larger the decompression algorithm, the more information a message can store in the same amount of space. It also looks more random. This is why jazz can convey so many more shades of emotion than say generic pop music. But it takes time to develop this decompression algorithm. This is why it’s a flex to understand subtlety; it shows you have put time in a skill. </p>
<p>Meaning to all messages is a construct of humans. Nothing has inherent meaning. I disagree with Hofsdater on this one. </p>
<p>Do not lose hope in the ultimate aim of understanding! It will set you free.</p>
<p>Snow crash, the diamond age, neuromancer: beautiful portrayals of emergent systems. The drummers. Panther moderns. Distributed, leaderless societal systems. </p>
<p>Not just low attention span, modern world has low emotional attention span. Feel extremely happy and extremely sad in the same minute. Music as a shortcut to emotion. </p>
<p>I see my conscious experience as this irrevocably self-referential microcosm.  </p>
<p>I dream of a world in which we are judged on the nature of our minds rather than the form of our bodies. </p>
<p>From where does our happiness stem and to what extent can we control it? I am on a theoretical search for truth yet get sidetracked by the need to be liked. If I neglect the latter urge, I am no longer happy. If I am no longer happy, I become a less effective learner. Is there a way to sidestep this whole hassle? Maybe to become liked without searching for it</p>
<p>I think I need to stop saying what people want to hear.</p>
<p>There is no reason experience has to be “rendered” linearly. </p>
<p>I recognize the total disorder, the total scope, the total fleetingness of things. </p>
<p>I have seen, been indescribably scared of, death my whole life. Not death, but all that is lost, never to appear again. Memories. 90% of experience ceases to exist. It’s like it never happened.</p>
<p>What even should I do???</p>
<p>A hopelessness. But to what do I owe this hopelessness to?</p>
<p>Bacon says there are three kinds of ambition, listed from degenerate to noble. The advancement of yourself, the advancement of your tribe, and the advancement of humans across the universe. Can one not extend this progression to all living things, or all intelligent beings?</p>
<p>I believe in a heaven indescribable and perhaps unreachable by man; that which comes with the understanding of all things.</p>
<p>Brutal impermanence of not just things, but mental states, convictions, memories, thoughts, tasks, personality, emotion, outlook.</p>
<p>Try recording a short voice recording after each chapter to solidify recall and understanding.</p>
<p>I say things often because I find the act of having said the thing to be funny, not necessarily because the thing is funny. </p>
<p>We reward people that do not write what they exactly mean by engaging in discussions about their writing.</p>
<p>The first step to not judging yourself might be to suspend judgement of others. </p>
<p>Absentminded introspection is a short-term gain. It is tempting because it feels like you are learning something, feeling something, but nothing that doesn't stick will ever help you in the long run. Give no heed to the thoughts you cannot permanently articulate. You should prioritize the smallest permanent things (math homework) over the largest fleeting thing (contemplating life). Any realization that is not made permanent will be almost immediately lost. Writing provides a much needed temporal permanence to thought processes. </p>
<p>words are futile devices</p>
<p>We do not hate a foe whom we are confident we can overcome. Thus to relinquish hate requires the ultimate form of self confidence.</p>
<p>Will vs intellect? Passion vs reason?</p>
<p>For someone that cannot predict the future, whether or not a system is deterministic makes no difference. This is why we should still behave morally and with virtue, making good decisions, even if free will is nonexistent. As present agents that cannot predict the future, we experience a form of “virtual” free will. </p>
<p>Normativity must come before any form of applied philosophy. Unless you aim only to study, and not to shape. </p>
<p>The problem of might=right is a problem of the individual, but never the collective, good. </p>
<p>Define time</p>
<p>What prevents time from flowing backwards?</p>
<p>All judgement is a form of simplification. We need to simplify the world through our senses to be able to fit in our brains. </p>
<p>Scripta manent, verba volant </p>
<p>Good architecture is fractal-like: detail at each level. </p>
<p>Greatness comes primarily from the curbing of extremes.</p>
<p>Dualism/Materialism<br />
Realism/Idealism<br />
Empiricism/Nativism</p>
<p>Will start writing at the top (scrolling gets too long) -------------^</p>

        
    </body>
</html>